{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICACIÓN DE EMOCIONES UTILIZANDO BASE DE DATOS DEAP\n",
    "\n",
    "## Organización de las bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Librerías Necesarias Para el Código organizadas por tipo de llamado y orden alfabético.\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pickle\n",
    "import pywt\n",
    "from scipy import signal\n",
    "from sklearn import svm\n",
    "import statistics as stats\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Loading EEG and labels dataset made by the code organizer\n",
    "File= open('Wavelets_Excombatants/EEG.pckl', 'rb')\n",
    "EEG = pickle.load(File)\n",
    "File.close()\n",
    "\n",
    "y = np.ones(150)\n",
    "y[50:100] = y[50:100]*2\n",
    "y[100:150] = y[100:150]*3\n",
    "\n",
    "label_matrix = y\n",
    "\n",
    "# Dimensions\n",
    "num_valences= 3\n",
    "num_channels= 62\n",
    "num_trials= 50\n",
    "num_rois = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 50, 62, 128)\n"
     ]
    }
   ],
   "source": [
    "label_matrix.shape\n",
    "print(EEG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USANDO DWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, according to the nyquist theorem, and noted the sample rate fixed in 128 Hz the sub bands will be:\n",
    "\n",
    "#### 32 to 64\n",
    "#### 16 to 32\n",
    "#### 8 to 16\n",
    "#### 4 to 8\n",
    "#### 2 to 4\n",
    "\n",
    "## But if we consider that brain rhythms are::\n",
    "\n",
    "#### Gamma: (30, 45)\n",
    "#### Beta: (12, 30)\n",
    "#### Alpha: (8, 12)\n",
    "#### Theta: (4, 8)\n",
    "#### Delta: (0, 4)\n",
    "\n",
    "\n",
    "## Then, to capture and separate most of the brain rhythms, we can use only\n",
    "#### 32 to 64     >>> Gamma\n",
    "#### 16 to 32     >>> High Beta\n",
    "#### 8 to 16     >>> Alpha\n",
    "#### 4 to 8    >>> Theta\n",
    "#### 2 to 4    >>> Delta\n",
    "\n",
    "\n",
    "## Which mean that we need 5 levels of decomposition for DWT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function plot_wavelet is unused\n",
    "def plot_wavelet(DWT_values,_values_f,subj,trial):\n",
    "    for n, c_D in enumerate(DWT_values):\n",
    "        len_D = len(DWT_values)\n",
    "        print(c_D.shape)\n",
    "        print(len_D)\n",
    "        fft_vals = np.absolute(np.fft.rfft(c_D[subj,trial]))\n",
    "        plt.figure()\n",
    "        plt.plot(fft_vals[1:-1])\n",
    "        if n ==(0):\n",
    "            plt.title(\"cA_{0} ,{1}\".format(n, _values_f[n]))\n",
    "        else:\n",
    "            plt.title(\"cD_{0}, {1}\".format(n+1, _values_f[n]))\n",
    "        plt.xlabel(\"Instances\")\n",
    "        plt.ylabel(\"Energy\")\n",
    "    plt.show()\n",
    "\n",
    "# Function characterization is used to create region of interest (ROI) clustering channels by indexes, then \n",
    "# we return several vectors according to the experiment, i.e. if the experiment has valences or not, if it will\n",
    "# combine information of rois or bands or even both with features, etc.\n",
    "\n",
    "def characterization(Filtered_Data,num_valences,num_trials,num_channels,wave,kind):\n",
    "    #Wavelet transform calculation, it is specified the dataset to transform, wavelet type and decomposition level\n",
    "    DWT_values= pywt.wavedec(Filtered_Data,wave,mode='sp1', level=4)\n",
    "    DWT_values = DWT_values[0:5]\n",
    "    len_D = len(DWT_values)\n",
    "    \n",
    "    ROI_1 = [0, 1, 2, 3, 4, 8, 9, 10, 18]\n",
    "    ROI_2 = [5, 6, 7, 14, 15, 16, 17]\n",
    "    ROI_3 = [11, 12, 13, 19, 20, 21, 22]\n",
    "    ROI_4 = [23, 24, 32, 33, 41, 42, 50]\n",
    "    ROI_5 = [30, 31, 39, 40, 48, 49, 56]\n",
    "    ROI_6 = [25, 26, 27, 28, 29, 34, 35, 36, 37, 38]\n",
    "    ROI_7 = [43, 44, 45, 46, 47, 51, 52, 53, 54, 55]\n",
    "    ROI_8 = [57, 58, 59, 60, 61]\n",
    "    ROIS = [ROI_1, ROI_2, ROI_3, ROI_4, ROI_5, ROI_6, ROI_7, ROI_8] #vector of regions of interest, each index is a channel\n",
    "    \n",
    "    ROI_ALL=[[]]*8\n",
    "    for i in range(8):\n",
    "        ROI_ALL[i] = [[]]*(len_D)\n",
    "    #Features_Wavelet store the data transform dividing into EEG Rhythms\n",
    "    Features_Stats=np.zeros([num_valences,len(DWT_values),num_trials,len(ROIS),8])\n",
    "    #print(len(ROI_ALL))\n",
    "    for roi in range(len(ROIS)):\n",
    "        for band in range(len(DWT_values)):\n",
    "            ROI_ALL[roi][band]=(np.mean(DWT_values[band][:,:,ROIS[roi],:],axis=2)) # we compute the mean of all channels of the same ROI\n",
    "            #Statistical Features\n",
    "            Features_Stats[:,band,:,roi,0] = np.max(ROI_ALL[roi][band],axis=2) # max value feature\n",
    "            Features_Stats[:,band,:,roi,1] = np.min(ROI_ALL[roi][band],axis=2) # min value feature\n",
    "            Features_Stats[:,band,:,roi,2] = np.mean(ROI_ALL[roi][band],axis=2) # mean\n",
    "            Features_Stats[:,band,:,roi,3] = np.var(ROI_ALL[roi][band],axis=2) # variance\n",
    "            Features_Stats[:,band,:,roi,4] = np.std(ROI_ALL[roi][band],axis=2) # standard deviation\n",
    "            Features_Stats[:,band,:,roi,5] = np.median(ROI_ALL[roi][band],axis=2) # median\n",
    "            Features_Stats[:,band,:,roi,6] = kurtosis(ROI_ALL[roi][band],axis=2) # kurtosis\n",
    "            Features_Stats[:,band,:,roi,7] = skew(ROI_ALL[roi][band],axis=2) #skewness\n",
    "            \n",
    "    #in this part, we organize the dimensions to later take to the classifier\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats,1,2)\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats_ROI,2,3)\n",
    "    Features_Stats_ROI = Features_Stats_ROI.reshape(num_valences,num_trials,len_D*len(ROIS),8)\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats_ROI,1,2)\n",
    "    Features_Stats_Bands = Features_Stats.reshape(num_valences,len_D,num_trials,len(ROIS)*8)\n",
    "    Features_Stats_Rois = Features_Stats.reshape(num_valences,len(ROIS),num_trials,len_D*8)\n",
    "    \n",
    "    Features_Stats_ValenceBands = np.swapaxes(Features_Stats,0,1)\n",
    "    Features_Stats_ValenceBands = np.swapaxes(Features_Stats_ValenceBands,1,2)\n",
    "    Features_Stats_ValenceBands = Features_Stats_ValenceBands.reshape(len_D,num_trials,num_valences,len(ROIS)*8)\n",
    "    Features_Stats_ValenceBands = Features_Stats_ValenceBands.reshape(len_D,num_trials,num_valences*len(ROIS)*8)\n",
    "    \n",
    "    Features_Stats_All = np.swapaxes(Features_Stats_ValenceBands,0,1)\n",
    "    #Features_Stats_ALL = np.swapaxes(Features_Stats_ALL,2,3)\n",
    "    Features_Stats_All = Features_Stats_All.reshape(num_trials,num_valences*len(ROIS)*8*len(DWT_values))\n",
    "    Features_Stats_ValencesRois = np.swapaxes(Features_Stats,0,2)\n",
    "    Features_Stats_ValencesRois = Features_Stats_ValencesRois.reshape(num_trials,len(DWT_values),num_valences*len(ROIS)*8)\n",
    "    Features_Stats_ValencesRois = np.swapaxes(Features_Stats_ValencesRois,0,1)\n",
    "    \n",
    "    Features_Stats_Valencesbands = np.swapaxes(Features_Stats,0,2)\n",
    "    Features_Stats_Valencesbands = Features_Stats_Valencesbands.reshape(num_trials,len(ROIS),num_valences*len(DWT_values)*8)\n",
    "    Features_Stats_Valencesbands = np.swapaxes(Features_Stats_Valencesbands,0,1)\n",
    "  \n",
    "    #\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats,1,2)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,2,3)\n",
    "    Features_Stats_Valences = Features_Stats_Valences.reshape(num_valences,num_trials,len_D*len(ROIS),8)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,0,1)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,1,2)\n",
    "    Features_Stats_Valences = Features_Stats_Valences.reshape(num_trials,len_D*len(ROIS),num_valences*8)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,0,1)\n",
    "    \n",
    "    Features_Stats_original = Features_Stats\n",
    "    Features_Stats=Features_Stats.reshape(num_valences,len_D,num_trials,64)\n",
    "    \n",
    "    # Return the vector according to the input    \n",
    "    if kind == 'complete' or kind == 0:\n",
    "        return Features_Stats\n",
    "    elif kind == 'ROI' or kind ==1:\n",
    "        return Features_Stats_ROI\n",
    "    elif kind == 'all' or kind ==2:\n",
    "        return Features_Stats_All\n",
    "    elif kind == \"valroi\" or kind ==3:\n",
    "        return Features_Stats_ValencesRois\n",
    "    elif kind == \"valences\" or kind ==4:\n",
    "        return Features_Stats_Valences\n",
    "    elif kind == \"original\" or kind == 5:\n",
    "        return Features_Stats_original\n",
    "    elif kind == 'bands' or kind ==6:\n",
    "        return Features_Stats_Bands\n",
    "    elif kind == \"rois\" or kind ==7:\n",
    "        return Features_Stats_Rois\n",
    "    elif kind == \"valencesbans\" or kind ==8:\n",
    "        return Features_Stats_Valencesbands\n",
    "                                                              \n",
    "    else:\n",
    "        raise NameError('Invalid kind of output')\n",
    "\n",
    "\n",
    "# This funtion is used to find the hyperparameter c and gamma\n",
    "def svc_param_selection(X, y, nfolds,Gamma):\n",
    "    Cs = 1.**np.arange(0,1)\n",
    "    #gammas = 2.**np.arange(-8,8)\n",
    "    param_grid = {'C':Cs}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf',gamma=Gamma,class_weight = 'balanced'),param_grid,  cv=nfolds)\n",
    "   # print(y)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 40, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "Feature_Stats=characterization(EEG,3,50,62,'sym8',1)\n",
    "print(Feature_Stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f (3, 50, 40, 8)\n",
      "u (3, 50, 5, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "flatten=characterization(EEG,3,50,62,'sym8',1)\n",
    "flatten = np.swapaxes(flatten, 1,2)\n",
    "unflatten=characterization(EEG,3,50,62,'sym8',5)\n",
    "unflatten = np.swapaxes(unflatten,1,2)\n",
    "#unflatten = np.swapaxes(unflatten,2,3)\n",
    "\n",
    "print(\"f\",flatten.shape)\n",
    "print(\"u\",unflatten.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_2 = flatten\n",
    "num_valences = 3\n",
    "num_bands = 5\n",
    "num_rois = 8\n",
    "unflatten_2 = np.zeros([num_valences,50,num_bands,num_rois])\n",
    "\n",
    "for valence in range(3):\n",
    "    for i in range(0,8):\n",
    "        for j in range(0,4):\n",
    "            unflatten_2[valence,0,j,i] = flatten_2[valence,0,j+i*num_bands,3]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM KERNEL RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 40 bands: \n",
    "### Here it was performed a classification for each valence and it was combined the bands and ROIs in a single dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando Wavelet: sym8\n",
      "[1. 2. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 3. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 1. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 3. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 1. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 1. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 1. 1. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 2. 2. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 2. 2. 1. 2.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 3.] [1. 1. 1. 1. 1.]\n",
      "[1. 3. 1. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 2. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 2. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[2. 3. 3. 2. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[1. 1. 2. 3. 1.] [1. 1. 1. 1. 1.]\n",
      "[3. 1. 3. 1. 1.] [1. 1. 1. 1. 1.]\n",
      "[2. 2. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 2. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 3. 3. 3. 3.] [1. 1. 1. 1. 1.]\n",
      "[3. 2. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 3. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 3. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 2. 3.] [2. 2. 2. 2. 2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 2. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 1. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 3. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 3. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 3. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 3. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 1. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 1. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 3. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 3. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 1. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 3. 1. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 1. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 1. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 2. 3.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 3. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 1. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 1.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 2. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[1. 1. 2. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 3. 2. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 3. 3. 3. 2.] [2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 1. 2.] [2. 2. 2. 2. 2.]\n",
      "[3. 3. 2. 3. 3.] [2. 2. 2. 2. 2.]\n",
      "[3. 2. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 3. 2.] [3. 3. 3. 3. 3.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 3. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 2. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 2. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 3. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 2. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 2. 2. 2.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 3. 3. 1. 2.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 2. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 1. 3. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 2. 3. 1. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 1. 3. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 3. 1. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 2. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 1. 1. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 3. 1. 2. 1.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[2. 3. 3. 2. 3.] [3. 3. 3. 3. 3.]\n",
      "[1. 1. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "[3. 2. 3. 3. 3.] [3. 3. 3. 3. 3.]\n",
      "INICIO TEST\n",
      "[0.41333333 0.42       0.32       0.29333333 0.41333333 0.38666667\n",
      " 0.31333333 0.39333333 0.36666667 0.79333333 0.40666667 0.40666667\n",
      " 0.30666667 0.46       0.54       0.32666667 0.29333333 0.34\n",
      " 0.30666667 0.51333333 0.32       0.35333333 0.32       0.35333333\n",
      " 0.44666667 0.38       0.37333333 0.41333333 0.36       0.45333333\n",
      " 0.35333333 0.35333333 0.44       0.36666667 0.6        0.36666667\n",
      " 0.32       0.31333333 0.38666667 0.32666667]\n",
      "(40,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(40, 150, 8)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(40,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(40,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(40,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "SE GUARDÓ EL ARCHIVO sym8_valences_bandrois\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences = 3\n",
    "N_Band= 40\n",
    "CrossVal = KFold(n_splits=30,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],1)\n",
    "    Features_Stats = np.concatenate((Features_Stats[0],Features_Stats[1],Features_Stats[2]),axis=1)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds,N_Band])\n",
    "    \n",
    "    \n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "#             Xtrain = scaler.fit_transform(Xtrain)\n",
    "#             Xtest = scaler.transform(Xtest)\n",
    "#             Xtrain = normalize(Xtrain)\n",
    "#             Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[0]*Xtrain[0].var())\n",
    "            Gamma = \"auto\"\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced',decision_function_shape = 'ovr')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold],SVM_Prediction_test,zero_division=1,average=\"micro\")\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold],SVM_Prediction_test)\n",
    "            print(SVM_Prediction_test,ytest)\n",
    "        fold+=1\n",
    "    #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "    print(F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'bandrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    \n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 5 bands:\n",
    "### Here it was performed a classification for each valence and it was combined the rois and statistical featues in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando Wavelet: sym8\n",
      "INICIO TEST\n",
      "[0.34666667 0.38       0.42       0.36       0.58666667] [0. 0. 0. 0. 0.] [0.24729649 0.20231988 0.28448784 0.20264912 0.32632635]\n",
      "(5,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(5, 150, 64)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(5,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(5,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(5,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "SE GUARDÓ EL ARCHIVO sym8_valences_bands\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=30,shuffle=False)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],6)\n",
    "    Features_Stats = np.concatenate((Features_Stats[0],Features_Stats[1],Features_Stats[2]),axis=1)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    \n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "#             Xtrain = scaler.fit_transform(Xtrain)\n",
    "#             Xtest = scaler.transform(Xtest)\n",
    "#             Xtrain = normalize(Xtrain)\n",
    "#             Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Gamma = \"auto\"\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold],SVM_Prediction_test,zero_division=1,average=\"micro\")\n",
    "#             ACC_test_fold[fold,band]= acc(y_test[fold],SVM_Prediction_test)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "    #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "    print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'bands'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_test_fold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 8 rois:\n",
    "### Here it was performed a classification for each valence and it was combined bands and statistical featues in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 50, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features_Stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando Wavelet: sym8\n",
      "INICIO TEST\n",
      "[0.36666667 0.22       0.25333333 0.39333333 0.3        0.36\n",
      " 0.31333333 0.32666667] [0.36666667 0.22       0.25333333 0.39333333 0.3        0.36\n",
      " 0.31333333 0.32666667] [0.23711226 0.18867962 0.26297444 0.33658415 0.27202941 0.26532998\n",
      " 0.30847294 0.25024433]\n",
      "(8,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(8, 150, 40)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(8,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(8,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(8,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "SE GUARDÓ EL ARCHIVO sym8_valences_rois\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences =3\n",
    "N_Band=8\n",
    "CrossVal = KFold(n_splits=30,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],7)\n",
    "    Features_Stats = np.concatenate((Features_Stats[0],Features_Stats[1],Features_Stats[2]),axis=1)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    \n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "#                 Xtrain = scaler.fit_transform(Xtrain)\n",
    "#                 Xtest = scaler.transform(Xtest)\n",
    "#                 Xtrain = normalize(Xtrain)\n",
    "#                 Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold],SVM_Prediction_test,zero_division=1,average=\"micro\")\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold],SVM_Prediction_test)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "    #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "    print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'rois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 40 bands and no-valences:\n",
    "### Here it was classified combining the bands and ROIs in a single dimension, and valences with statistical features in another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "N_Band=40\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],4)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "    #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "    print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_bandrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 5 bands and no-valences:\n",
    "### Here it was classified combining the valences, bands and ROIs in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],3)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "       \n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valencesrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F1_test_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 8 Rois and no-valences:\n",
    "### Here it was classified combining the valences, bands and ROIs in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=8\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],8)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "       \n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valencesbands'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR USE ALL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],2)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    \n",
    "    y_test = []\n",
    "  \n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "     \n",
    "        Xtrain,Xtest = Features_Stats[train_index,:], Features_Stats[test_index,:]\n",
    "        scaler = MinMaxScaler();\n",
    "        Xtrain = scaler.fit_transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        Xtrain = normalize(Xtrain)\n",
    "        Xtest = normalize(Xtest)\n",
    "\n",
    "        Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        Median= stats.median(Distances)\n",
    "        Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "        Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "        SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Xtrain,ytrain)\n",
    "        #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"FOLD:\",fold,\"\\n ytest:\",ytest,\" SVM_Prediction_test:\",SVM_Prediction_test)\n",
    "\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "\n",
    "    F1_test = np.mean(F1_test_fold[:])\n",
    "    ACC_test= np.mean(ACC_test_fold[:])\n",
    "    STD_F1_test = np.std(F1_test_fold[:])\n",
    "    STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_all'\n",
    "    \n",
    "     #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1:\",F1_test)\n",
    "print(\"ACC:\",ACC_test)\n",
    "print(\"STD_F1:\",STD_F1_test)\n",
    "print(\"STD_ACC:\",STD_ACC_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR USE ALL VALENCES VECTORIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=50,shuffle=False)\n",
    "C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],2)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test[fold,band]= SVM_Classifier.predict(Xtest)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = f1_score(y_test,SVM_Prediction_test[:,band])\n",
    "        ACC_test[band] = acc(y_test,SVM_Prediction_test[:,band])\n",
    "    print(F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    import pickle\n",
    "    file= open('Wavelets_Results_ROIs/F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open('Wavelets_Results_ROIs/ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ACC_test)\n",
    "mean=np.mean(ACC_test)\n",
    "sd = np.std(ACC_test)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import f1_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Subjects = 32\n",
    "N_Emociones=4\n",
    "N_Band=6\n",
    "CrossVal = LeaveOneOut()\n",
    "N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[0,0,:,:]))\n",
    "print(N_folds)\n",
    "C = 2.**np.arange(-15,19)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix_C3)\n",
    "N_cs = len(C)\n",
    "Best_C_Matrix=np.zeros([Subjects,N_Emociones,N_folds,N_Band])\n",
    "F1_train = np.zeros([Subjects,N_Emociones,N_folds,N_Band,N_cs])\n",
    "F1_test = np.zeros([Subjects,N_Emociones,N_Band])\n",
    "SVM_Prediction_test=np.zeros([Subjects,N_Emociones,N_folds,N_Band])\n",
    "y_test = np.zeros([Subjects,N_Emociones,N_folds])\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "for emo in range(N_Emociones):\n",
    "    for sub in range(Subjects):\n",
    "        print('Análisis Sujeto: ',sub)\n",
    "        if sub==26 and emo==2:\n",
    "            print(emo,' SALTO DE SUJETO ',sub)\n",
    "            sub+=1\n",
    "        emocion=emo\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[sub,5,:,:])):\n",
    "            ytrain, ytest = label_threshold_matrix_5[sub,train_index,emocion], label_threshold_matrix_5[sub,test_index,emocion]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            y_test[sub,emo,fold] = ytest\n",
    "            for band in range(0,N_Band):\n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[sub,band,train_index,:]), (Features_Stats_Wavelets[sub,band,test_index,:])\n",
    "                Best_C= -10000\n",
    "                Best_F1=0\n",
    "                for c in range(len(C)):\n",
    "                    Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                    Median= stats.median(Distances)\n",
    "                    Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                    SVM_Classifier= svm.SVC(kernel='rbf',C=C[c],gamma=Gamma)\n",
    "                    SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                    SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                    SVM_Prediction_test[sub,emo,fold,band]= SVM_Classifier.predict(Xtest)\n",
    "                    F1_train[sub,emo,fold,band,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "                    if F1_train[sub,emo,fold,band,c]>Best_F1:\n",
    "                        Best_C_Matrix[sub,emo,fold,band]=C[c]\n",
    "                        Best_C= C[c]\n",
    "                        Best_F1=F1_train[sub,emo,fold,band,c]\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        for band in range(0,N_Band):\n",
    "            F1_test[sub,emo,band] = f1_score(y_test[sub,emo,:],SVM_Prediction_test[sub,emo,:,band],average='macro')\n",
    "        print(F1_test[sub])\n",
    "\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
