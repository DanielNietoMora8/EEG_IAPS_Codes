{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICACIÓN DE EMOCIONES UTILIZANDO BASE DE DATOS DEAP\n",
    "\n",
    "## Organización de las bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Librerías Necesarias Para el Código organizadas por tipo de llamado y orden alfabético.\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pickle\n",
    "import pywt\n",
    "from scipy import signal\n",
    "from sklearn import svm\n",
    "import statistics as stats\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Loading EEG and labels dataset made by the code organizer\n",
    "File= open('Wavelets_Excombatants/EEG.pckl', 'rb')\n",
    "EEG = pickle.load(File)\n",
    "File.close()\n",
    "\n",
    "File= open('Wavelets_Excombatants/y.pckl', 'rb')\n",
    "label_matrix= pickle.load(File)\n",
    "File.close()\n",
    "\n",
    "# Dimensions\n",
    "num_valences= 3\n",
    "num_channels= 62\n",
    "num_trials= 50\n",
    "num_rois = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 50, 62, 128)\n"
     ]
    }
   ],
   "source": [
    "label_matrix.shape\n",
    "print(EEG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USANDO DWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, according to the nyquist theorem, and noted the sample rate fixed in 128 Hz the sub bands will be:\n",
    "\n",
    "#### 32 to 64\n",
    "#### 16 to 32\n",
    "#### 8 to 16\n",
    "#### 4 to 8\n",
    "#### 2 to 4\n",
    "\n",
    "## But if we consider that brain rhythms are::\n",
    "\n",
    "#### Gamma: (30, 45)\n",
    "#### Beta: (12, 30)\n",
    "#### Alpha: (8, 12)\n",
    "#### Theta: (4, 8)\n",
    "#### Delta: (0, 4)\n",
    "\n",
    "\n",
    "## Then, to capture and separate most of the brain rhythms, we can use only\n",
    "#### 32 to 64     >>> Gamma\n",
    "#### 16 to 32     >>> High Beta\n",
    "#### 8 to 16     >>> Alpha\n",
    "#### 4 to 8    >>> Theta\n",
    "#### 2 to 4    >>> Delta\n",
    "\n",
    "\n",
    "## Which mean that we need 5 levels of decomposition for DWT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function plot_wavelet is unused\n",
    "def plot_wavelet(DWT_values,_values_f,subj,trial):\n",
    "    for n, c_D in enumerate(DWT_values):\n",
    "        len_D = len(DWT_values)\n",
    "        print(c_D.shape)\n",
    "        print(len_D)\n",
    "        fft_vals = np.absolute(np.fft.rfft(c_D[subj,trial]))\n",
    "        plt.figure()\n",
    "        plt.plot(fft_vals[1:-1])\n",
    "        if n ==(0):\n",
    "            plt.title(\"cA_{0} ,{1}\".format(n, _values_f[n]))\n",
    "        else:\n",
    "            plt.title(\"cD_{0}, {1}\".format(n+1, _values_f[n]))\n",
    "        plt.xlabel(\"Instances\")\n",
    "        plt.ylabel(\"Energy\")\n",
    "    plt.show()\n",
    "\n",
    "# Function characterization is used to create region of interest (ROI) clustering channels by indexes, then \n",
    "# we return several vectors according to the experiment, i.e. if the experiment has valences or not, if it will\n",
    "# combine information of rois or bands or even both with features, etc.\n",
    "\n",
    "def characterization(Filtered_Data,num_valences,num_trials,num_channels,wave,kind):\n",
    "    #Wavelet transform calculation, it is specified the dataset to transform, wavelet type and decomposition level\n",
    "    DWT_values= pywt.wavedec(Filtered_Data,wave,mode='sp1', level=4)\n",
    "    DWT_values = DWT_values[0:4]\n",
    "    len_D = len(DWT_values)\n",
    "    \n",
    "    ROI_1 = [0, 1, 2, 3, 4, 8, 9, 10, 18]\n",
    "    ROI_2 = [5, 6, 7, 14, 15, 16, 17]\n",
    "    ROI_3 = [11, 12, 13, 19, 20, 21, 22]\n",
    "    ROI_4 = [23, 24, 32, 33, 41, 42, 50]\n",
    "    ROI_5 = [30, 31, 39, 40, 48, 49, 56]\n",
    "    ROI_6 = [25, 26, 27, 28, 29, 34, 35, 36, 37, 38]\n",
    "    ROI_7 = [43, 44, 45, 46, 47, 51, 52, 53, 54, 55]\n",
    "    ROI_8 = [57, 58, 59, 60, 61]\n",
    "    ROIS = [ROI_1, ROI_2, ROI_3, ROI_4, ROI_5, ROI_6, ROI_7, ROI_8] #vector of regions of interest, each index is a channel\n",
    "    \n",
    "    ROI_ALL=[[]]*8\n",
    "    for i in range(8):\n",
    "        ROI_ALL[i] = [[]]*(len_D)\n",
    "    #Features_Wavelet store the data transform dividing into EEG Rhythms\n",
    "    Features_Stats=np.zeros([num_valences,len(DWT_values),num_trials,len(ROIS),8])\n",
    "    #print(len(ROI_ALL))\n",
    "    for roi in range(len(ROIS)):\n",
    "        for band in range(len(DWT_values)):\n",
    "            ROI_ALL[roi][band]=(np.mean(DWT_values[band][:,:,ROIS[roi],:],axis=2)) # we compute the mean of all channels of the same ROI\n",
    "            #Statistical Features\n",
    "            Features_Stats[:,band,:,roi,0] = np.max(ROI_ALL[roi][band],axis=2) # max value feature\n",
    "            Features_Stats[:,band,:,roi,1] = np.min(ROI_ALL[roi][band],axis=2) # min value feature\n",
    "            Features_Stats[:,band,:,roi,2] = np.mean(ROI_ALL[roi][band],axis=2) # mean\n",
    "            Features_Stats[:,band,:,roi,3] = np.var(ROI_ALL[roi][band],axis=2) # variance\n",
    "            Features_Stats[:,band,:,roi,4] = np.std(ROI_ALL[roi][band],axis=2) # standard deviation\n",
    "            Features_Stats[:,band,:,roi,5] = np.median(ROI_ALL[roi][band],axis=2) # median\n",
    "            Features_Stats[:,band,:,roi,6] = kurtosis(ROI_ALL[roi][band],axis=2) # kurtosis\n",
    "            Features_Stats[:,band,:,roi,7] = skew(ROI_ALL[roi][band],axis=2) #skewness\n",
    "            \n",
    "    #in this part, we organize the dimensions to later take to the classifier\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats,1,2)\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats_ROI,2,3)\n",
    "    Features_Stats_ROI = Features_Stats_ROI.reshape(num_valences,num_trials,len_D*len(ROIS),8)\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats_ROI,1,2)\n",
    "    Features_Stats_Bands = Features_Stats.reshape(num_valences,len_D,num_trials,len(ROIS)*8)\n",
    "    Features_Stats_Rois = Features_Stats.reshape(num_valences,len(ROIS),num_trials,len_D*8)\n",
    "    \n",
    "    Features_Stats_ValenceBands = np.swapaxes(Features_Stats,0,1)\n",
    "    Features_Stats_ValenceBands = np.swapaxes(Features_Stats_ValenceBands,1,2)\n",
    "    Features_Stats_ValenceBands = Features_Stats_ValenceBands.reshape(len_D,num_trials,num_valences,len(ROIS)*8)\n",
    "    Features_Stats_ValenceBands = Features_Stats_ValenceBands.reshape(len_D,num_trials,num_valences*len(ROIS)*8)\n",
    "    \n",
    "    Features_Stats_All = np.swapaxes(Features_Stats_ValenceBands,0,1)\n",
    "    #Features_Stats_ALL = np.swapaxes(Features_Stats_ALL,2,3)\n",
    "    Features_Stats_All = Features_Stats_All.reshape(num_trials,num_valences*len(ROIS)*8*len(DWT_values))\n",
    "    Features_Stats_ValencesRois = np.swapaxes(Features_Stats,0,2)\n",
    "    Features_Stats_ValencesRois = Features_Stats_ValencesRois.reshape(num_trials,len(DWT_values),num_valences*len(ROIS)*8)\n",
    "    Features_Stats_ValencesRois = np.swapaxes(Features_Stats_ValencesRois,0,1)\n",
    "    \n",
    "    Features_Stats_Valencesbands = np.swapaxes(Features_Stats,0,2)\n",
    "    Features_Stats_Valencesbands = Features_Stats_Valencesbands.reshape(num_trials,len(ROIS),num_valences*len(DWT_values)*8)\n",
    "    Features_Stats_Valencesbands = np.swapaxes(Features_Stats_Valencesbands,0,1)\n",
    "  \n",
    "    \n",
    "    Features_Stats_Valences =  np.swapaxes(Features_Stats,0,3)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_ROI,1,3)\n",
    "    Features_Stats_Valences = Features_Stats_Valences.reshape(len(ROIS)*len_D,num_trials,num_valences*8)\n",
    "    \n",
    "    Features_Stats_original = Features_Stats\n",
    "    Features_Stats=Features_Stats.reshape(num_valences,len_D,num_trials,64)\n",
    "    \n",
    "    # Return the vector according to the input    \n",
    "    if kind == 'complete' or kind == 0:\n",
    "        return Features_Stats\n",
    "    elif kind == 'ROI' or kind ==1:\n",
    "        return Features_Stats_ROI\n",
    "    elif kind == 'all' or kind ==2:\n",
    "        return Features_Stats_All\n",
    "    elif kind == \"valroi\" or kind ==3:\n",
    "        return Features_Stats_ValencesRois\n",
    "    elif kind == \"valences\" or kind ==4:\n",
    "        return Features_Stats_Valences\n",
    "    elif kind == \"original\" or kind == 5:\n",
    "        return Features_Stats_original\n",
    "    elif kind == 'bands' or kind ==6:\n",
    "        return Features_Stats_Bands\n",
    "    elif kind == \"rois\" or kind ==7:\n",
    "        return Features_Stats_Rois\n",
    "    elif kind == \"valencesbans\" or kind ==8:\n",
    "        return Features_Stats_Valencesbands\n",
    "                                                              \n",
    "    else:\n",
    "        raise NameError('Invalid kind of output')\n",
    "\n",
    "# Unused\n",
    "def graficar(F1_test,emocion):  \n",
    "    Bandas=np.arange(1,6)\n",
    "    contador=1\n",
    "    Emocion=['Valence','Arousal','Dominance','Liking']\n",
    "    for s in range(0,32):\n",
    "        plt.figure(contador,figsize=(6,5))\n",
    "        plt.title('Sujeto de estudio: '+str(s+1)+'  Emocion: '+Emocion[emocion])\n",
    "        plt.bar(Bandas, F1_test[s,emocion,:], align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan'])\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('Frequency Band')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.show()\n",
    "        contador+=1\n",
    "\n",
    "# This funtion is used to find the hyperparameter c and gamma\n",
    "def svc_param_selection(X, y, nfolds,Gamma):\n",
    "    Cs = 1.**np.arange(0,1)\n",
    "    #gammas = 2.**np.arange(-8,8)\n",
    "    param_grid = {'C':Cs}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf',gamma=Gamma,class_weight = 'balanced'),param_grid,  cv=nfolds)\n",
    "   # print(y)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[2, 4, 6], [1, 3, 5]])\n",
    "print(a)\n",
    "b = np.reshape(a,6)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_Stats_1=characterization(EEG,3,50,62,'sym8',1)\n",
    "print(Feature_Stats_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flatten=Features_Stats_1=characterization(EEG,3,50,62,'sym8',1)\n",
    "flatten = np.swapaxes(flatten, 1,2)\n",
    "unflatten=Features_Stats_1=characterization(EEG,3,50,62,'sym8',5)\n",
    "unflatten = np.swapaxes(unflatten,1,2)\n",
    "#unflatten = np.swapaxes(unflatten,2,3)\n",
    "\n",
    "print(\"f\",flatten.shape)\n",
    "print(\"u\",unflatten.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unflatten[0,0,1,1,:])\n",
    "print(flatten[0,0,5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unflatten_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_2 = flatten\n",
    "num_valences = 3\n",
    "num_bands = 4\n",
    "num_rois = 8\n",
    "unflatten_2 = np.zeros([num_valences,50,num_bands,num_rois])\n",
    "\n",
    "for valence in range(3):\n",
    "    for i in range(0,8):\n",
    "        for j in range(0,4):\n",
    "            unflatten_2[valence,0,j,i] = flatten_2[valence,0,j+i*num_bands,3]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unflatten_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unflatten_2[0,0,0,2])\n",
    "print(flatten_2[0,0,8,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flatten_2[0,0,0,:])\n",
    "print(unflatten_2[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unflatten[0,0,:,:,0].shape\n",
    "unflatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM KERNEL RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 40 bands: \n",
    "### Here it was performed a classification for each valence and it was combined the bands and ROIs in a single dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando Wavelet: sym8 Valencia : 0\n",
      "INICIO TEST\n",
      "[[0.46666667 0.48       0.41333333 0.32       0.53333333 0.6\n",
      "  0.52       0.57333333 0.48       0.58666667 0.14666667 0.68\n",
      "  0.61333333 0.45333333 0.65333333 0.64       0.28       0.53333333\n",
      "  0.61333333 0.50666667 0.49333333 0.41333333 0.48       0.42666667\n",
      "  0.53333333 0.62666667 0.44       0.50666667 0.48       0.46666667\n",
      "  0.44       0.49333333]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "Analizando Wavelet: sym8 Valencia : 1\n",
      "INICIO TEST\n",
      "[[0.46666667 0.48       0.41333333 0.32       0.53333333 0.6\n",
      "  0.52       0.57333333 0.48       0.58666667 0.14666667 0.68\n",
      "  0.61333333 0.45333333 0.65333333 0.64       0.28       0.53333333\n",
      "  0.61333333 0.50666667 0.49333333 0.41333333 0.48       0.42666667\n",
      "  0.53333333 0.62666667 0.44       0.50666667 0.48       0.46666667\n",
      "  0.44       0.49333333]\n",
      " [0.38666667 0.46666667 0.46666667 0.42666667 0.58666667 0.58666667\n",
      "  0.42666667 0.49333333 0.57333333 0.54666667 0.34666667 0.6\n",
      "  0.50666667 0.64       0.48       0.36       0.34666667 0.38666667\n",
      "  0.48       0.41333333 0.56       0.32       0.56       0.49333333\n",
      "  0.44       0.54666667 0.54666667 0.25333333 0.41333333 0.25333333\n",
      "  0.38666667 0.56      ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n",
      "Analizando Wavelet: sym8 Valencia : 2\n",
      "INICIO TEST\n",
      "[[0.46666667 0.48       0.41333333 0.32       0.53333333 0.6\n",
      "  0.52       0.57333333 0.48       0.58666667 0.14666667 0.68\n",
      "  0.61333333 0.45333333 0.65333333 0.64       0.28       0.53333333\n",
      "  0.61333333 0.50666667 0.49333333 0.41333333 0.48       0.42666667\n",
      "  0.53333333 0.62666667 0.44       0.50666667 0.48       0.46666667\n",
      "  0.44       0.49333333]\n",
      " [0.38666667 0.46666667 0.46666667 0.42666667 0.58666667 0.58666667\n",
      "  0.42666667 0.49333333 0.57333333 0.54666667 0.34666667 0.6\n",
      "  0.50666667 0.64       0.48       0.36       0.34666667 0.38666667\n",
      "  0.48       0.41333333 0.56       0.32       0.56       0.49333333\n",
      "  0.44       0.54666667 0.54666667 0.25333333 0.41333333 0.25333333\n",
      "  0.38666667 0.56      ]\n",
      " [0.49333333 0.54666667 0.32       0.49333333 0.4        0.30666667\n",
      "  0.48       0.46666667 0.41333333 0.49333333 0.70666667 0.32\n",
      "  0.38666667 0.36       0.56       0.57333333 0.17333333 0.57333333\n",
      "  0.42666667 0.61333333 0.30666667 0.45333333 0.44       0.52\n",
      "  0.50666667 0.33333333 0.57333333 0.58666667 0.44       0.17333333\n",
      "  0.36       0.26666667]]\n",
      "(3, 32)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(3, 32, 50, 8)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(3, 32)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(3, 32)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(3, 32)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "SE GUARDÓ EL ARCHIVO sym8_valences_bandrois\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences = 3\n",
    "N_Band= 32\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],1)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds,N_Band])\n",
    "    \n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence))\n",
    "\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[valence,1,:,:]),label_matrix):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            #print(ytest.shape,y_test.shape)\n",
    "            y_test.append(ytest)\n",
    "                        \n",
    "            for band in range(0,N_Band):        \n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats[valence,band,train_index,:]), (Features_Stats[valence,band,test_index,:])\n",
    "                scaler = MinMaxScaler();\n",
    "                Xtrain = scaler.fit_transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                Xtrain = normalize(Xtrain)\n",
    "                Xtest = normalize(Xtest)\n",
    "\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= stats.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "                SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "                SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "                F1_test_fold[fold,valence,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "                ACC_test_fold[fold,valence,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "                #print(y_test)\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        \n",
    "        for band in range(0,N_Band):\n",
    "            #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "            F1_test[valence,band] = np.mean(F1_test_fold[:,valence,band])\n",
    "            ACC_test[valence,band]= np.mean(ACC_test_fold[:,valence,band])\n",
    "            STD_F1_test[valence,band] = np.std(F1_test_fold[:,valence,band])\n",
    "            STD_ACC_test[valence,band] = np.std(ACC_test_fold[:,valence,band])\n",
    "        print(F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'bandrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    \n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 5 bands:\n",
    "### Here it was performed a classification for each valence and it was combined the rois and statistical featues in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences =3\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],6)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence))\n",
    "\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[valence,1,:,:])):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            #print(ytest.shape,y_test.shape)\n",
    "            y_test.append(ytest)\n",
    "                        \n",
    "            for band in range(0,N_Band):        \n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats[valence,band,train_index,:]), (Features_Stats[valence,band,test_index,:])\n",
    "                scaler = MinMaxScaler();\n",
    "                Xtrain = scaler.fit_transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                Xtrain = normalize(Xtrain)\n",
    "                Xtest = normalize(Xtest)\n",
    "\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= stats.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "                SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "                SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "                F1_test_fold[fold,valence,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "                ACC_test_fold[fold,valence,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "                #print(y_test)\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        for band in range(0,N_Band):\n",
    "            #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "            F1_test[valence,band] = np.mean(F1_test_fold[:,valence,band])\n",
    "            ACC_test[valence,band]= np.mean(ACC_test_fold[:,valence,band])\n",
    "            STD_F1_test[valence,band] = np.std(F1_test_fold[:,valence,band])\n",
    "            STD_ACC_test[valence,band] = np.std(ACC_test_fold[:,valence,band])\n",
    "        print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'bands'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 8 rois:\n",
    "### Here it was performed a classification for each valence and it was combined bands and statistical featues in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences =3\n",
    "N_Band=8\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],7)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence))\n",
    "\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[valence,1,:,:])):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            #print(ytest.shape,y_test.shape)\n",
    "            y_test.append(ytest)\n",
    "                        \n",
    "            for band in range(0,N_Band):        \n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats[valence,band,train_index,:]), (Features_Stats[valence,band,test_index,:])\n",
    "                scaler = MinMaxScaler();\n",
    "                Xtrain = scaler.fit_transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                Xtrain = normalize(Xtrain)\n",
    "                Xtest = normalize(Xtest)\n",
    "\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= stats.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "                SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "                SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "                F1_test_fold[fold,valence,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "                ACC_test_fold[fold,valence,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "                #print(y_test)\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        for band in range(0,N_Band):\n",
    "            #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "            F1_test[valence,band] = np.mean(F1_test_fold[:,valence,band])\n",
    "            ACC_test[valence,band]= np.mean(ACC_test_fold[:,valence,band])\n",
    "            STD_F1_test[valence,band] = np.std(F1_test_fold[:,valence,band])\n",
    "            STD_ACC_test[valence,band] = np.std(ACC_test_fold[:,valence,band])\n",
    "        print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'rois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 40 bands and no-valences:\n",
    "### Here it was classified combining the bands and ROIs in a single dimension, and valences with statistical features in another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_Stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando Wavelet: sym8\n",
      "INICIO TEST\n",
      "[0.45333333 0.50666667 0.92       0.44       0.45333333 0.68\n",
      " 0.94666667 0.48       0.44       0.66666667 0.92       0.34666667\n",
      " 0.52       0.70666667 0.93333333 0.49333333 0.50666667 0.66666667\n",
      " 0.94666667 0.56       0.4        0.70666667 0.94666667 0.36\n",
      " 0.41333333 0.70666667 0.94666667 0.34666667 0.52       0.68\n",
      " 0.93333333 0.41333333] [0.5  0.62 0.9  0.46 0.46 0.7  0.94 0.5  0.48 0.72 0.9  0.3  0.46 0.72\n",
      " 0.92 0.48 0.5  0.7  0.96 0.58 0.44 0.72 0.96 0.34 0.44 0.72 0.96 0.34\n",
      " 0.58 0.72 0.94 0.46] [0.42037021 0.4909854  0.21664102 0.43939352 0.42037021 0.46647615\n",
      " 0.20396078 0.41182521 0.43939352 0.43204938 0.21664102 0.37094474\n",
      " 0.41182521 0.44542115 0.21081851 0.42290004 0.40133112 0.46188022\n",
      " 0.20396078 0.43939352 0.43204938 0.44542115 0.20396078 0.4207929\n",
      " 0.41397799 0.44542115 0.20396078 0.40529824 0.44301994 0.46647615\n",
      " 0.21081851 0.38040914]\n",
      "(32,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(32, 50, 24)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(32,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(32,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "(32,)\n",
      "Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\n",
      "SE GUARDÓ EL ARCHIVO sym8_bandrois\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "N_Band=32\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],4)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "    #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "    print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_bandrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 5 bands and no-valences:\n",
    "### Here it was classified combining the valences, bands and ROIs in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],3)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "       \n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valencesrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F1_test_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 8 Rois and no-valences:\n",
    "### Here it was classified combining the valences, bands and ROIs in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=8\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],8)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "       \n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valencesbands'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR USE ALL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],2)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    \n",
    "    y_test = []\n",
    "  \n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "     \n",
    "        Xtrain,Xtest = Features_Stats[train_index,:], Features_Stats[test_index,:]\n",
    "        scaler = MinMaxScaler();\n",
    "        Xtrain = scaler.fit_transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        Xtrain = normalize(Xtrain)\n",
    "        Xtest = normalize(Xtest)\n",
    "\n",
    "        Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        Median= stats.median(Distances)\n",
    "        Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "        Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "        SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Xtrain,ytrain)\n",
    "        #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"FOLD:\",fold,\"\\n ytest:\",ytest,\" SVM_Prediction_test:\",SVM_Prediction_test)\n",
    "\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "\n",
    "    F1_test = np.mean(F1_test_fold[:])\n",
    "    ACC_test= np.mean(ACC_test_fold[:])\n",
    "    STD_F1_test = np.std(F1_test_fold[:])\n",
    "    STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_all'\n",
    "    \n",
    "     #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "                \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1:\",F1_test)\n",
    "print(\"ACC:\",ACC_test)\n",
    "print(\"STD_F1:\",STD_F1_test)\n",
    "print(\"STD_ACC:\",STD_ACC_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR USE ALL VALENCES VECTORIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=50,shuffle=False)\n",
    "C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],2)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test[fold,band]= SVM_Classifier.predict(Xtest)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = f1_score(y_test,SVM_Prediction_test[:,band])\n",
    "        ACC_test[band] = acc(y_test,SVM_Prediction_test[:,band])\n",
    "    print(F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    import pickle\n",
    "    file= open('Wavelets_Results_ROIs/F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open('Wavelets_Results_ROIs/ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente 👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏👏\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÓ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ACC_test)\n",
    "mean=np.mean(ACC_test)\n",
    "sd = np.std(ACC_test)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import f1_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Subjects = 32\n",
    "N_Emociones=4\n",
    "N_Band=6\n",
    "CrossVal = LeaveOneOut()\n",
    "N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[0,0,:,:]))\n",
    "print(N_folds)\n",
    "C = 2.**np.arange(-15,19)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix_C3)\n",
    "N_cs = len(C)\n",
    "Best_C_Matrix=np.zeros([Subjects,N_Emociones,N_folds,N_Band])\n",
    "F1_train = np.zeros([Subjects,N_Emociones,N_folds,N_Band,N_cs])\n",
    "F1_test = np.zeros([Subjects,N_Emociones,N_Band])\n",
    "SVM_Prediction_test=np.zeros([Subjects,N_Emociones,N_folds,N_Band])\n",
    "y_test = np.zeros([Subjects,N_Emociones,N_folds])\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "for emo in range(N_Emociones):\n",
    "    for sub in range(Subjects):\n",
    "        print('Análisis Sujeto: ',sub)\n",
    "        if sub==26 and emo==2:\n",
    "            print(emo,' SALTO DE SUJETO ',sub)\n",
    "            sub+=1\n",
    "        emocion=emo\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[sub,5,:,:])):\n",
    "            ytrain, ytest = label_threshold_matrix_5[sub,train_index,emocion], label_threshold_matrix_5[sub,test_index,emocion]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            y_test[sub,emo,fold] = ytest\n",
    "            for band in range(0,N_Band):\n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[sub,band,train_index,:]), (Features_Stats_Wavelets[sub,band,test_index,:])\n",
    "                Best_C= -10000\n",
    "                Best_F1=0\n",
    "                for c in range(len(C)):\n",
    "                    Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                    Median= stats.median(Distances)\n",
    "                    Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                    SVM_Classifier= svm.SVC(kernel='rbf',C=C[c],gamma=Gamma)\n",
    "                    SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                    SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                    SVM_Prediction_test[sub,emo,fold,band]= SVM_Classifier.predict(Xtest)\n",
    "                    F1_train[sub,emo,fold,band,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "                    if F1_train[sub,emo,fold,band,c]>Best_F1:\n",
    "                        Best_C_Matrix[sub,emo,fold,band]=C[c]\n",
    "                        Best_C= C[c]\n",
    "                        Best_F1=F1_train[sub,emo,fold,band,c]\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        for band in range(0,N_Band):\n",
    "            F1_test[sub,emo,band] = f1_score(y_test[sub,emo,:],SVM_Prediction_test[sub,emo,:,band],average='macro')\n",
    "        print(F1_test[sub])\n",
    "\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
