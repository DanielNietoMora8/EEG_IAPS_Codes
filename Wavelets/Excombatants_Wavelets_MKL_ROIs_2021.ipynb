{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICACIÃ“N DE EMOCIONES UTILIZANDO BASE DE DATOS DEAP\n",
    "\n",
    "## OrganizaciÃ³n de las bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 39, 39) (39, 1)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  7.5304e-01 -3.0348e-01  1e+00  6e-17  4e+00\n",
      " 1:  7.4936e-01  6.8717e-01  6e-02  1e-16  2e-01\n",
      " 2:  7.1453e-01  6.9393e-01  2e-02  5e-17  8e-16\n",
      " 3:  7.1026e-01  7.0811e-01  2e-03  1e-16  6e-16\n",
      " 4:  7.0930e-01  7.0925e-01  4e-05  1e-16  4e-16\n",
      " 5:  7.0927e-01  7.0927e-01  4e-07  2e-16  4e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "#LibrerÃ­as Necesarias Para el CÃ³digo organizadas por tipo de llamado y orden alfabÃ©tico.\n",
    "import csv\n",
    "#import h5py\n",
    "import mne\n",
    "import scipy\n",
    "import statistics\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import scipy.io as sio\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "from scipy import signal\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import svm\n",
    "from ckaweightedMKL1 import ckaweightedK\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#from unipath import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGA DE LAS CARACTRERÃSTICAS Y LAS ETIQUETAS BINARIZADAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf) #Imprime todos los valores de los arrays, sirve para visualizar mejor los datos\n",
    "\n",
    "\n",
    "import pickle\n",
    "File= open('Wavelets_Excombatants/y.pckl', 'rb')\n",
    "label_matrix= pickle.load(File)\n",
    "File.close()\n",
    "\n",
    "num_valences= 3\n",
    "num_rois = 8\n",
    "num_channels= 62\n",
    "num_trials= 50\n",
    "#To assess the performance of the C in each emotion, later to evaluate is not necessary.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(label_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MixKer(K,eta):\n",
    "    Kn= np.zeros_like((K[1]))\n",
    "    for i in range(len(eta)):\n",
    "        Kn= Kn + eta[i]*(K[i])\n",
    "    return(Kn)\n",
    "\n",
    "def KerRBF(X):\n",
    "    d= spatial.distance.pdist(X)\n",
    "    gamma= 1/(X.shape[1]*X.var())\n",
    "    K= -spatial.distance.squareform(d)*gamma\n",
    "    K= np.exp(K)\n",
    "    return(K)\n",
    "    \n",
    "def KerLin(X):\n",
    "    K = np.matmul(X,X.T)\n",
    "    return(K)\n",
    "\n",
    "def graficar(F1_test,Subjects,emocion,save):  \n",
    "    Bandas=np.arange(1,5)\n",
    "    Subject= np.arange(1,Subjects+1)\n",
    "    contador=1\n",
    "   \n",
    "\n",
    "    plt.figure(contador,figsize=(6,5))\n",
    "    plt.title('MKL Emocion: ')\n",
    "    plt.bar(Subject, F1_test[:], align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan'])\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('Frequency Band')\n",
    "    plt.ylabel('F1 Score')\n",
    "    if save== 'y':\n",
    "        plt.savefig('FiguresMKL_5/'+'C2_Improved')\n",
    "    plt.show()\n",
    "    contador+=1\n",
    "    \n",
    "    \n",
    "def svc_param_selection(y, nfolds,Kernel_train_Wavelets):\n",
    "    Cs = 1.**np.arange(-1,1)\n",
    "    #gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C':Cs}\n",
    "    clf=svm.SVC(kernel='precomputed',class_weight = 'balanced')\n",
    "    clf.fit(Kernel_train_Wavelets,y)\n",
    "    grid_search = GridSearchCV(clf,param_grid,  cv=nfolds)\n",
    "    grid_search.fit(Kernel_train, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n",
    "\n",
    "def Moda(N_Emociones,Subjects,Best_C_Matrix):\n",
    "    Mode_C=np.zeros([N_Emociones])\n",
    "    Mode_aux=np.zeros([Subjects,N_Emociones])\n",
    "    Mode_aux2=np.zeros([Subjects,N_Emociones])\n",
    "    for emo in range(0,N_Emociones):\n",
    "        print('Emocion: ',emo)\n",
    "        for sub in range(Subjects):\n",
    " \n",
    "            a= Best_C_Matrix[sub,emo,:]\n",
    "            a=a.tolist()\n",
    "            Mode_aux[sub,emo]= max(a,key=a.count)           \n",
    "      \n",
    "        try:\n",
    "            c= Mode_aux[:,emo]\n",
    "            c=c.tolist()\n",
    "            Mode_C[emo]=max(c,key=c.count)\n",
    "        except:\n",
    "            print('Nada3')\n",
    "    \n",
    "    print(' Mode Valence: ',Mode_C[0],'\\n Mode Arousal: ',Mode_C[1],'\\n Mode Dominance: ',Mode_C[2], '\\n Mode Liking: ',Mode_C[3])\n",
    "    return Mode_C\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM RBF Multiple Kernel Learning MKL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 5 bands: \n",
    "### Here it was performed a classification for each valence and it was combined the ROIs and statistical features in a single dimension, keeping the bands dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = np.ones(31)\n",
    "b = np.ones(19)*-1\n",
    "c = np.concatenate((a,b))\n",
    "#print(c)\n",
    "np.random.shuffle(c)\n",
    "label_matrix = c\n",
    "label_matrix.shape = [50,1]\n",
    "label_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Csr = 0.1**np.arange(-10,10)\n",
    "Csr[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 50, 64)\n",
      "Analizando Wavelet: sym8 Valencia : 0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [1. 1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [-1. -1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.88\n",
      "Analizando Wavelet: sym8 Valencia : 1\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.84\n",
      "Analizando Wavelet: sym8 Valencia : 2\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.98\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3, 25, 5)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "SE GUARDÃ“ EL ARCHIVO sym8_valences_bands_easy_MKL\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 5\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_valences_bands'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds,Valences])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences])\n",
    "    F1_test = np.zeros([Valences])\n",
    "    ACC_test = np.zeros([Valences])\n",
    "    STD_F1_test = np.zeros([Valences])\n",
    "    STD_ACC_test = np.zeros([Valences])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([Valences,N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence)) \n",
    "\n",
    "        for band in range(0,N_Band):\n",
    "            scaler = MinMaxScaler()\n",
    "            K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[valence,band,:,:]))\n",
    "            K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "            K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[valence,1,:,:])):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "            y_test.append(ytest)\n",
    "\n",
    "            #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "        #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "            Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "            Ktrain =  K[:,train_index,:]\n",
    "            Ktrain = Ktrain[:,:,train_index]\n",
    "            Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "            Ktest = K[:,test_index,:]\n",
    "            Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "        #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "            #earlystop = EarlyStopping(\n",
    "            #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "            #            patience=5,     #max number of acceptable negative steps\n",
    "            #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "            #            metric='auc',   #the metric we monitor\n",
    "            #            )\n",
    "\n",
    "            #scheduler = ReduceOnWorsening()\n",
    "\n",
    "            #mkl = GRAM(\n",
    "            #max_iter=1000,          \n",
    "            #learning_rate=.01,      \n",
    "            #callbacks=[earlystop],\n",
    "            #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "            #print(mkl)\n",
    "            #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "        #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "            clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "            weights_train = clf_Linear_Easy.weights\n",
    "            #print(weights_train)\n",
    "\n",
    "            #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "            #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "            #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "            #aux=np.ones(len(weights_train))\n",
    "            #weights_train = aux-weights_train\n",
    "            #print(weights_train)\n",
    "            weights[valence,fold]=weights_train\n",
    "            Kernel_train= MixKer(Ktrain,weights_train)\n",
    "            Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "        #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\"\n",
    "            clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "            ##print(K_average)\n",
    "            #print ('training EasyMKL...', end='')\n",
    "            clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "            #print(K_Linear_average)\n",
    "            Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "            Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "            \"\"\"\n",
    "        #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "            #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            #Median= statistics.median(Distances)\n",
    "            Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "            SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "            SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "            F1_test_fold[fold,valence] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,valence]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold,valence],\"F1:\",F1_test_fold[fold,valence],\"C:\",Parameters_grid['C'])\n",
    "            #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "            fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test[valence] = np.mean(F1_test_fold[:,valence])\n",
    "        ACC_test[valence]= np.mean(ACC_test_fold[:,valence])\n",
    "        STD_F1_test[valence] = np.std(F1_test_fold[:,valence])\n",
    "        STD_ACC_test[valence] = np.std(ACC_test_fold[:,valence])\n",
    "        print(ACC_test[valence])\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valences_bands_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 40 bands: \n",
    "### Here it was performed a classification for each valence and it was combined the bands and ROIs in a single dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 40, 50, 8)\n",
      "Analizando Wavelet: sym8 Valencia : 0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [ 1. -1.] SVM: [-1.  1.] ACC: 0.0 F1: 0.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "INICIO TEST\n",
      "0.9333333333333332\n",
      "Analizando Wavelet: sym8 Valencia : 1\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "INICIO TEST\n",
      "0.9866666666666666\n",
      "Analizando Wavelet: sym8 Valencia : 2\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "INICIO TEST\n",
      "0.9866666666666666\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3, 25, 40)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "SE GUARDÃ“ EL ARCHIVO sym8_valences_bandrois_easy_MKL\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 40\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_valences_bandrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds,Valences])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences])\n",
    "    F1_test = np.zeros([Valences])\n",
    "    ACC_test = np.zeros([Valences])\n",
    "    STD_F1_test = np.zeros([Valences])\n",
    "    STD_ACC_test = np.zeros([Valences])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([Valences,N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence)) \n",
    "\n",
    "        for band in range(0,N_Band):\n",
    "            scaler = MinMaxScaler()\n",
    "            K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[valence,band,:,:]))\n",
    "            K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "            K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[valence,1,:,:]),label_matrix):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "            y_test.append(ytest)\n",
    "\n",
    "            #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "        #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "            Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "            Ktrain =  K[:,train_index,:]\n",
    "            Ktrain = Ktrain[:,:,train_index]\n",
    "            Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "            Ktest = K[:,test_index,:]\n",
    "            Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "        #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "            #earlystop = EarlyStopping(\n",
    "            #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "            #            patience=5,     #max number of acceptable negative steps\n",
    "            #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "            #            metric='auc',   #the metric we monitor\n",
    "            #            )\n",
    "\n",
    "            #scheduler = ReduceOnWorsening()\n",
    "\n",
    "            #mkl = GRAM(\n",
    "            #max_iter=1000,          \n",
    "            #learning_rate=.01,      \n",
    "            #callbacks=[earlystop],\n",
    "            #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "            #print(mkl)\n",
    "            #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "        #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "            clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "            weights_train = clf_Linear_Easy.weights\n",
    "            #print(weights_train)\n",
    "\n",
    "            #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "            #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "            #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "            #aux=np.ones(len(weights_train))\n",
    "            #weights_train = aux-weights_train\n",
    "            #print(weights_train)\n",
    "            weights[valence,fold]=weights_train\n",
    "            Kernel_train= MixKer(Ktrain,weights_train)\n",
    "            Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "        #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\"\n",
    "            clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "            ##print(K_average)\n",
    "            #print ('training EasyMKL...', end='')\n",
    "            clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "            #print(K_Linear_average)\n",
    "            Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "            Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "            \"\"\"\n",
    "        #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "            #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            #Median= statistics.median(Distances)\n",
    "            Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "            SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "            SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "            F1_test_fold[fold,valence] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,valence]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold,valence],\"F1:\",F1_test_fold[fold,valence])\n",
    "            #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "            fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test[valence] = np.mean(F1_test_fold[:,valence])\n",
    "        ACC_test[valence]= np.mean(ACC_test_fold[:,valence])\n",
    "        STD_F1_test[valence] = np.std(F1_test_fold[:,valence])\n",
    "        STD_ACC_test[valence] = np.std(ACC_test_fold[:,valence])\n",
    "        print(F1_test[valence])\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valences_bandrois_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 5 bands and no-valences: \n",
    "### Here it was performed a classification mixing the Valences, ROIs and statistical features in a single dimension, keeping the bands dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 50, 192)\n",
      "Analizando Wavelet: sym8\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.04\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.08\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.12\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.16\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.2\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.24\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.28\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.32\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.36\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.4\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.44\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.48\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.52\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.56\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.6\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "INICIO TEST\n",
      "0.62\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.66\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.7\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.74\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.76\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.8\n",
      "y_test: [-1. -1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.82\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.86\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.9\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.94\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(25, 5)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "SE GUARDÃ“ EL ARCHIVO sym8_valencesrois_easy_MKL\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 5\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_valencesrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave]) \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        scaler = MinMaxScaler()\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "        K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "        K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        #Median= statistics.median(Distances)\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test = np.mean(F1_test_fold[:])\n",
    "        ACC_test= np.mean(ACC_test_fold[:])\n",
    "        STD_F1_test = np.std(F1_test_fold[:])\n",
    "        STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        print(ACC_test)\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valencesrois_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 40 bands and no-valences: \n",
    "### Here it was performed a classification mixing the Valences, ROIs and statistical features in a single dimension, keeping the bands dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 50, 24)\n",
      "Analizando Wavelet: sym8\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.04\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.08\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.12\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.16\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.2\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.24\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.28\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.32\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.36\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.4\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.44\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.48\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.52\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.56\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.6\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "INICIO TEST\n",
      "0.62\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.66\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.7\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.74\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.78\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.82\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.86\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.9\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.94\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.98\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(25, 40)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "()\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "SE GUARDÃ“ EL ARCHIVO sym8_bandrois_easy_MKL\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 40\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_bandrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave]) \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        scaler = MinMaxScaler()\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "        K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "        K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        #Median= statistics.median(Distances)\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test = np.mean(F1_test_fold[:])\n",
    "        ACC_test= np.mean(ACC_test_fold[:])\n",
    "        STD_F1_test = np.std(F1_test_fold[:])\n",
    "        STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        print(ACC_test)\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_bandrois_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "0.06531972647421809\n",
      "[[0.01588725 0.02603322 0.01255076 0.01742709 0.04047021 0.03661889\n",
      "  0.01475814 0.01573334 0.0196073  0.03442284 0.03346093 0.02581269\n",
      "  0.00983011 0.04265883 0.03256541 0.030588   0.02293819 0.03663094\n",
      "  0.02054358 0.03953424 0.02803212 0.01317314 0.00971336 0.03065839\n",
      "  0.02521009 0.03553157 0.01827888 0.03335074 0.01812193 0.0327027\n",
      "  0.02194544 0.01875693 0.0117016  0.02918493 0.03263361 0.0347648\n",
      "  0.01530426 0.00878399 0.02045565 0.03362393]\n",
      " [0.01490839 0.02683937 0.01295598 0.01699162 0.03723336 0.03393349\n",
      "  0.0175431  0.01676833 0.01845027 0.03475902 0.03138633 0.0257514\n",
      "  0.01015534 0.03994963 0.0268482  0.03309152 0.03029085 0.03196323\n",
      "  0.0196741  0.04013993 0.03127073 0.01364894 0.01073404 0.03148556\n",
      "  0.02363907 0.04195682 0.01962914 0.03330971 0.01867045 0.03384001\n",
      "  0.02161804 0.01742275 0.01162579 0.02817327 0.03149624 0.03512121\n",
      "  0.01341665 0.00890024 0.02216689 0.03224098]\n",
      " [0.01456757 0.02522033 0.01391075 0.01797504 0.03863091 0.03508789\n",
      "  0.01474178 0.01488335 0.01910799 0.03283064 0.0339274  0.02850333\n",
      "  0.01064052 0.03920628 0.0304701  0.03541769 0.02832651 0.03256811\n",
      "  0.02131014 0.03837801 0.03067051 0.01428143 0.0099206  0.03515943\n",
      "  0.02411468 0.03971638 0.01616794 0.02750292 0.01954222 0.0342247\n",
      "  0.02165384 0.01827462 0.01167879 0.02483741 0.03180942 0.03468955\n",
      "  0.01627367 0.00907699 0.02174511 0.03295547]\n",
      " [0.0174564  0.02375402 0.01355978 0.0177034  0.04385111 0.03764178\n",
      "  0.01526428 0.01547487 0.02055438 0.03682219 0.03172944 0.02651831\n",
      "  0.00974523 0.03636332 0.0315673  0.02965711 0.02484049 0.03738919\n",
      "  0.01887018 0.03958789 0.03127565 0.0131195  0.01063289 0.03218649\n",
      "  0.02792319 0.04102674 0.018342   0.02345952 0.01856757 0.03234102\n",
      "  0.02050037 0.01819589 0.01126635 0.02669168 0.02988976 0.03338518\n",
      "  0.01498434 0.00893363 0.0217648  0.03716277]\n",
      " [0.01448661 0.02421994 0.01327979 0.01816696 0.0389272  0.03256863\n",
      "  0.01403499 0.01575559 0.02032652 0.03659583 0.0386496  0.03002492\n",
      "  0.01072225 0.03691034 0.03004608 0.02982648 0.02679749 0.03628884\n",
      "  0.02071526 0.03918151 0.031385   0.01274231 0.0101625  0.03379995\n",
      "  0.02600937 0.04043455 0.01427822 0.02897737 0.01877553 0.03307326\n",
      "  0.02347877 0.01786928 0.01208188 0.02678916 0.03111045 0.03389991\n",
      "  0.01311414 0.00956432 0.0219379  0.03299125]\n",
      " [0.01418898 0.02489285 0.01504657 0.01782715 0.04066955 0.03144007\n",
      "  0.01388901 0.01621293 0.02022661 0.03466282 0.03286358 0.02709071\n",
      "  0.01019225 0.03969564 0.03037    0.03184957 0.02942301 0.03091003\n",
      "  0.01977471 0.0426231  0.03096654 0.01280178 0.01201937 0.03060676\n",
      "  0.02601463 0.03658846 0.01787424 0.03388447 0.01966245 0.03477949\n",
      "  0.02187207 0.01805122 0.01139077 0.02533447 0.03226388 0.03251344\n",
      "  0.01524508 0.00944763 0.01892797 0.03590612]\n",
      " [0.01503025 0.02592693 0.01423072 0.01773808 0.04246509 0.0358459\n",
      "  0.01609481 0.01633079 0.01843893 0.03575892 0.03567309 0.02775532\n",
      "  0.010013   0.03775493 0.03012055 0.02996506 0.02668053 0.03246617\n",
      "  0.02086816 0.03700209 0.03285256 0.01347809 0.01089424 0.03261676\n",
      "  0.02626605 0.03836756 0.01703753 0.02728121 0.01811761 0.03326096\n",
      "  0.02322716 0.01868426 0.01095043 0.02763142 0.03244444 0.03371744\n",
      "  0.01320636 0.00944955 0.01985671 0.03450032]\n",
      " [0.01594496 0.02372449 0.01099367 0.01775154 0.04089913 0.03121578\n",
      "  0.01498561 0.01514449 0.01962029 0.03595242 0.03394727 0.03050195\n",
      "  0.0104192  0.04324949 0.0294671  0.03259516 0.03029854 0.03225625\n",
      "  0.01995198 0.04006385 0.03434324 0.01287209 0.01092878 0.03145617\n",
      "  0.02490986 0.03854626 0.01582332 0.03323105 0.01846743 0.03229964\n",
      "  0.02209292 0.01900035 0.01195813 0.02473014 0.02900431 0.03084092\n",
      "  0.01523099 0.0088124  0.02195149 0.03451731]\n",
      " [0.01748439 0.02395092 0.01339449 0.01814244 0.04119023 0.03948031\n",
      "  0.01490496 0.01532574 0.02117427 0.03254291 0.03136311 0.02500492\n",
      "  0.0100986  0.0373029  0.02989188 0.03135361 0.02948956 0.03678206\n",
      "  0.01913632 0.04187704 0.0299699  0.01343599 0.01047001 0.03294903\n",
      "  0.02550118 0.03911714 0.0186191  0.03000471 0.02002822 0.03317123\n",
      "  0.02118187 0.01781567 0.01123438 0.0252485  0.03035296 0.03386717\n",
      "  0.01334305 0.0094646  0.02129376 0.03304088]\n",
      " [0.01516259 0.02618425 0.01420512 0.01656166 0.04379224 0.03351615\n",
      "  0.01559401 0.01604577 0.02217731 0.03466987 0.03355372 0.02614152\n",
      "  0.01063447 0.03659653 0.03141525 0.0326904  0.0281924  0.03718872\n",
      "  0.02083741 0.03936368 0.02760607 0.01006744 0.00962591 0.03319934\n",
      "  0.02808443 0.03633877 0.01703237 0.03367743 0.01932893 0.03423166\n",
      "  0.02240221 0.01715073 0.01192056 0.02494911 0.03087464 0.03191381\n",
      "  0.01252228 0.00934909 0.0203363  0.03486584]\n",
      " [0.01608827 0.02643231 0.01346617 0.0180902  0.03989702 0.03404284\n",
      "  0.01519226 0.01704837 0.01993698 0.03441106 0.03563644 0.02663753\n",
      "  0.00980805 0.03637936 0.03283847 0.03337871 0.02477899 0.03056841\n",
      "  0.01995253 0.04135518 0.028627   0.01319951 0.01004956 0.03054149\n",
      "  0.02514727 0.04053196 0.01783792 0.02787153 0.01974409 0.03392034\n",
      "  0.02290943 0.0194586  0.01273156 0.02764386 0.03071538 0.031819\n",
      "  0.01437037 0.00833121 0.02211808 0.03649268]\n",
      " [0.01485545 0.02427235 0.01401736 0.01686462 0.03936788 0.03399938\n",
      "  0.01363777 0.0155289  0.01899872 0.03397562 0.03164449 0.0271582\n",
      "  0.01040921 0.04268344 0.03180834 0.03367217 0.02870377 0.03504467\n",
      "  0.01974715 0.04289456 0.03158622 0.01319352 0.00927714 0.0348586\n",
      "  0.02569161 0.04011728 0.01465229 0.03403742 0.02066496 0.03255951\n",
      "  0.02229919 0.01911063 0.01106286 0.02470443 0.03104929 0.02983508\n",
      "  0.01245557 0.00890947 0.02166615 0.03298473]\n",
      " [0.01596131 0.02549079 0.01306577 0.01744908 0.03810002 0.03328378\n",
      "  0.01457901 0.01552674 0.01934333 0.03333338 0.03210231 0.02963765\n",
      "  0.01256047 0.04100709 0.03466914 0.03161788 0.02827889 0.02906772\n",
      "  0.0204446  0.0414512  0.02870167 0.01132578 0.0108386  0.03539921\n",
      "  0.02603152 0.03677656 0.01490442 0.03208132 0.01727325 0.0367455\n",
      "  0.01988587 0.01814719 0.01456918 0.0255795  0.0301888  0.03197951\n",
      "  0.01552439 0.00914522 0.02212124 0.03581106]\n",
      " [0.0153903  0.02394787 0.01373338 0.0185645  0.04157387 0.03692976\n",
      "  0.0140393  0.0176924  0.0199912  0.03536543 0.03240528 0.02492591\n",
      "  0.01148918 0.03412912 0.02933576 0.03687679 0.03245029 0.03212233\n",
      "  0.02097755 0.0387626  0.03180666 0.01268646 0.01026746 0.03227651\n",
      "  0.02583124 0.04037968 0.01537638 0.02995063 0.02071245 0.03494194\n",
      "  0.02151177 0.01538211 0.01479761 0.02597304 0.0295802  0.03380318\n",
      "  0.01144403 0.00876009 0.02142754 0.03238816]\n",
      " [0.01624064 0.02414451 0.01410604 0.0180049  0.03979341 0.03265389\n",
      "  0.01369824 0.01622935 0.01979776 0.03622014 0.03174976 0.02679435\n",
      "  0.01047744 0.03746244 0.03305421 0.03388944 0.02725422 0.03383371\n",
      "  0.01770282 0.03935824 0.03236446 0.0130162  0.01040409 0.0346037\n",
      "  0.02697564 0.04176315 0.01624383 0.02978178 0.01934853 0.03370878\n",
      "  0.02520319 0.01515565 0.0114677  0.02517724 0.02924136 0.03118853\n",
      "  0.01488895 0.00960162 0.02245176 0.03494832]\n",
      " [0.01674345 0.02312207 0.01300029 0.02092235 0.03585092 0.03620815\n",
      "  0.01525861 0.01731424 0.02082965 0.03187988 0.0311616  0.0243721\n",
      "  0.01130655 0.03567777 0.0312086  0.03344102 0.02826919 0.03713523\n",
      "  0.01869594 0.03861283 0.03294301 0.01152469 0.01138698 0.03627953\n",
      "  0.02707463 0.04249204 0.0150908  0.03137629 0.01914439 0.03060386\n",
      "  0.02208133 0.01482188 0.01321685 0.02991746 0.03165904 0.03326192\n",
      "  0.01149371 0.00871152 0.02064735 0.0352623 ]\n",
      " [0.01722395 0.02115154 0.01213821 0.01865025 0.03704172 0.0333739\n",
      "  0.01715059 0.01800656 0.02053277 0.03770337 0.02872585 0.02742898\n",
      "  0.01338187 0.03238658 0.03364455 0.03185667 0.0265741  0.03170811\n",
      "  0.02220115 0.04382319 0.02771641 0.0132999  0.0095966  0.03454224\n",
      "  0.02434341 0.03599337 0.01372204 0.03158855 0.02284323 0.03461988\n",
      "  0.01967352 0.02028209 0.01348051 0.02755303 0.03070098 0.03578943\n",
      "  0.01256594 0.0093671  0.02179717 0.0358207 ]\n",
      " [0.01580782 0.02378023 0.01241856 0.01242781 0.04272065 0.03296163\n",
      "  0.01690347 0.01427007 0.01702861 0.03876865 0.03226505 0.03126537\n",
      "  0.00645224 0.03923227 0.03237004 0.03128407 0.02910656 0.03524878\n",
      "  0.02178694 0.04077332 0.03216997 0.01434859 0.01112528 0.03777531\n",
      "  0.02399188 0.03649674 0.01859483 0.02863264 0.01405868 0.03780687\n",
      "  0.02055813 0.01698186 0.00739005 0.02981657 0.03416207 0.03214913\n",
      "  0.01627405 0.00955675 0.01941371 0.03182477]\n",
      " [0.01375139 0.02428647 0.01384049 0.02044633 0.04195801 0.03847594\n",
      "  0.01676735 0.01629596 0.02107964 0.03340055 0.03230352 0.02566298\n",
      "  0.01117006 0.03334392 0.02805795 0.03679373 0.02880908 0.03099796\n",
      "  0.01924788 0.03596062 0.03217103 0.01315602 0.01184337 0.03560505\n",
      "  0.02851454 0.03416981 0.01758169 0.02956719 0.01786402 0.03559306\n",
      "  0.02171782 0.01735475 0.01451812 0.02902972 0.02990718 0.02836219\n",
      "  0.01775176 0.0094216  0.02150991 0.03171135]\n",
      " [0.01363871 0.0269646  0.01471466 0.01921634 0.03606758 0.03120688\n",
      "  0.0145579  0.01685119 0.02072737 0.03608576 0.03643791 0.02673382\n",
      "  0.01200747 0.04229649 0.03251899 0.03322913 0.02762764 0.03054028\n",
      "  0.01891959 0.03967146 0.02761164 0.01215839 0.00877543 0.03241245\n",
      "  0.02424573 0.04048245 0.01431198 0.03246018 0.02376248 0.03408727\n",
      "  0.02421139 0.01540544 0.01471039 0.0213936  0.03605787 0.03210628\n",
      "  0.01086071 0.00907526 0.02056784 0.03528944]\n",
      " [0.01781334 0.02245585 0.0124357  0.01972392 0.04124159 0.04013717\n",
      "  0.01164697 0.01594189 0.02264866 0.03336074 0.0330923  0.0200698\n",
      "  0.010586   0.03657764 0.02858903 0.0295761  0.02603329 0.03237312\n",
      "  0.01928522 0.04479362 0.03335959 0.01178341 0.00982295 0.03427555\n",
      "  0.02730093 0.04118752 0.01422945 0.02860173 0.01981954 0.03795623\n",
      "  0.0217765  0.01555729 0.01110183 0.03012824 0.02844374 0.03702296\n",
      "  0.01438023 0.00913934 0.01897068 0.03676035]\n",
      " [0.01585405 0.02422515 0.01537536 0.01834654 0.04623514 0.02976156\n",
      "  0.0117026  0.01258199 0.02140716 0.03901834 0.03510182 0.02727151\n",
      "  0.01133888 0.03624189 0.03149259 0.03157985 0.02657124 0.03122577\n",
      "  0.01853461 0.04470976 0.02776212 0.01371656 0.00893052 0.03140869\n",
      "  0.0248208  0.04451968 0.01642944 0.02815675 0.02252267 0.02731408\n",
      "  0.02644918 0.01741962 0.0102588  0.02447075 0.03109799 0.03499533\n",
      "  0.01543107 0.01011453 0.02270119 0.03290443]\n",
      " [0.01886563 0.02560986 0.0139014  0.01901057 0.03574736 0.03787724\n",
      "  0.01204679 0.01800665 0.02048193 0.03188312 0.03428781 0.02559145\n",
      "  0.01139396 0.0367664  0.02721848 0.03509746 0.02837004 0.03369925\n",
      "  0.01992169 0.04052432 0.03608879 0.0105161  0.00997121 0.03016923\n",
      "  0.02817312 0.03819867 0.01939617 0.03155416 0.01760367 0.03329284\n",
      "  0.02045984 0.0181993  0.01481067 0.02439015 0.02959639 0.03259976\n",
      "  0.01299595 0.00907487 0.02133536 0.03527232]\n",
      " [0.01781414 0.02350074 0.01562514 0.01499553 0.041219   0.03240759\n",
      "  0.01921889 0.0164386  0.01765125 0.03412659 0.03522728 0.02474452\n",
      "  0.00924982 0.03766829 0.02946554 0.03126899 0.02603784 0.03659171\n",
      "  0.02170397 0.03583853 0.03381366 0.01300239 0.01252452 0.02889989\n",
      "  0.02700185 0.03834115 0.01706429 0.02857383 0.02002244 0.03453116\n",
      "  0.02422555 0.01746452 0.01072928 0.02857825 0.03024993 0.03732493\n",
      "  0.01420897 0.00986677 0.01966977 0.03311288]\n",
      " [0.01405877 0.02730765 0.01457245 0.0178094  0.04466808 0.03331284\n",
      "  0.01734128 0.01698881 0.01867845 0.03366438 0.03497286 0.02960238\n",
      "  0.01142202 0.04466416 0.0303464  0.03211341 0.02589194 0.03303305\n",
      "  0.02108276 0.03552656 0.02801291 0.01243334 0.01022704 0.03066202\n",
      "  0.02733756 0.0386793  0.02070122 0.02755563 0.01824504 0.02990485\n",
      "  0.02211713 0.01758671 0.01385964 0.02045082 0.03398927 0.02925043\n",
      "  0.01208785 0.00937429 0.02415859 0.0363087 ]]\n"
     ]
    }
   ],
   "source": [
    "print(ACC_test)\n",
    "print(STD_F1_test)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNUSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "CrossVal= LeaveOneOut()\n",
    "N_Band= 5\n",
    "N_Trials= 50\n",
    "N_Rois = 8\n",
    "C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_valencesrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    \n",
    "    SVM_Prediction_test=np.zeros([N_folds])\n",
    "    y_test = np.zeros([N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "  \n",
    "    print('Analizando Wavelet: '+wave_name[wave]+' Valencia : ') \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        y_test[fold] = ytest\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test[fold] = ytest\n",
    "\n",
    "        Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[band,train_index,:]), (Features_Stats_Wavelets[band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        Median= statistics.median(Distances)\n",
    "        #Gamma= 1/(2*(Median**2))\n",
    "        Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Gamma,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',gamma=Gamma,C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test[fold]= SVM_Classifier.predict(Kernel_test)\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    F1_test = f1_score(y_test[:],SVM_Prediction_test[:])\n",
    "    ACC_test= acc(y_test[:],SVM_Prediction_test[:])\n",
    "    print(F1_test)\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valencesrois_easy'\n",
    "    #Pickle Save F1 Score\n",
    "    import pickle\n",
    "    file= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "CrossVal= LeaveOneOut()\n",
    "N_Band= 40\n",
    "N_Trials= 50\n",
    "C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_bandrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    SVM_Prediction_test=np.zeros([N_folds])\n",
    "    y_test = np.zeros([N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "   \n",
    "    print('Analizando Wavelet: '+wave_name[wave]) \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        y_test[fold] = ytest\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test[fold] = ytest\n",
    "\n",
    "        Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[band,train_index,:]), (Features_Stats_Wavelets[band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        Median= statistics.median(Distances)\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Gamma,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',gamma=Gamma,C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test[fold]= SVM_Classifier.predict(Kernel_test)\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "    #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    F1_test = f1_score(y_test[:],SVM_Prediction_test[:])\n",
    "    ACC_test = acc(y_test[:],SVM_Prediction_test[:])\n",
    "    print(F1_test)\n",
    "#graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_bandrois_easy'\n",
    "    #Pickle Save F1 Score\n",
    "    import pickle\n",
    "    file= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File= open('Wavelets_Results/F1_Score_'+'bior3.3_sparse'+'_MKL.pckl', 'rb')\n",
    "F1_test = pickle.load(File)\n",
    "File.close()\n",
    "print(F1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_test.tofile('Test_5\\F1_Test_KRBF_C3_MKL_Improved'+'.txt')\n",
    "#Best_C_Matrix.tofile('Test_5\\Best_C_Matrix_C2_MKL'+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRÃFICA DEL F1_SCORE PARA CADA SUJETO EN CADA BANDA Y PARA CADA C \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Subjects= 32\n",
    "CrossVal= LeaveOneOut()\n",
    "N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,1,:,:]))\n",
    "N_Band= 6\n",
    "N_Trials= 40\n",
    "N_Emociones=4\n",
    "C = 2.**np.arange(-15,19)\n",
    "N_cs = len(C)\n",
    "Best_C_Matrix=np.zeros([Subjects,N_Emociones,N_folds])\n",
    "F1_train = np.zeros([Subjects,N_Emociones,N_folds,N_cs])\n",
    "F1_test = np.zeros([Subjects,N_Emociones])\n",
    "SVM_Prediction_test=np.zeros([Subjects,N_Emociones,N_folds])\n",
    "y_test = np.zeros([Subjects,N_folds])\n",
    "K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "for emo in range(N_Emociones):\n",
    "    for sub in range(Subjects):\n",
    "        print('AnÃ¡lisis Sujeto: ',sub, 'EmociÃ³n: ',emo)\n",
    "        if (sub==26 and emo==2):\n",
    "            sub+=1\n",
    "            \n",
    "        for band in range(0,N_Band):\n",
    "            K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[sub,band,:,:]))\n",
    "\n",
    "        fold = 0\n",
    "        emocion=emo\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[sub,1,:,:])):\n",
    "            ytrain, ytest = label_threshold_matrix_5[sub,train_index,emocion], label_threshold_matrix_5[sub,test_index,emocion]\n",
    "            y_test[sub,fold] = ytest\n",
    "            ytrainMKL, ytestMKL = label_matrix[sub,train_index,emocion], label_matrix[sub,test_index,emocion]\n",
    "            ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "            y_test[sub,fold] = ytest\n",
    "\n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[sub,band,train_index,:]), (Features_Stats_Wavelets[sub,band,test_index,:])\n",
    "\n",
    "        #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "            Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "            Ktrain =  K[:,train_index,:]\n",
    "            Ktrain = Ktrain[:,:,train_index]\n",
    "            Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "            Ktest = K[:,test_index,:]\n",
    "            Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "        #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "            #print(Ktrain.shape, ytrain2.shape)\n",
    "            weights_train = ckaweightedK(Ktrain,ytrain2)\n",
    "            #print(weights_train)\n",
    "            Kernel_train= MixKer(Ktrain,weights_train)\n",
    "            Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "        #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\"\n",
    "            clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "            ##print(K_average)\n",
    "            #print ('training EasyMKL...', end='')\n",
    "            clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "            #print(K_Linear_average)\n",
    "            Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "            Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "            \"\"\"\n",
    "        #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "            Best_C= -10000\n",
    "            Best_F1=0\n",
    "            for c in range(len(C)):\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= statistics.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                SVM_Classifier= svm.SVC(kernel='precomputed',C=C[c])\n",
    "                SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "                SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "                SVM_Prediction_test[sub,emo,fold]= SVM_Classifier.predict(Kernel_test)\n",
    "                F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "                if F1_train[sub,emo,fold,c]>Best_F1:\n",
    "                    Best_C_Matrix[valence,fold]=C[c]\n",
    "                    Best_C= C[c]\n",
    "                    Best_F1=F1_train[valence,fold,c]\n",
    "            fold+=1\n",
    "\n",
    "\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test[sub,emo] = f1_score(y_test[sub,:],SVM_Prediction_test[sub,emo,:],average='macro')\n",
    "        #print(F1_test[sub,band,c])\n",
    "        #time.sleep(4)\n",
    "    graficar(F1_test,Subjects,emocion)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "graficar(F1_test,Subjects,3)\n",
    "Moda(N_Emociones,Subjects,Best_C_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_test.tofile('Test\\F1_Test_Customlib_RBF_Lineal_C3_'+Emocion[emocion]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band=['Theta','Low Alpha', 'High Alpha', 'Alha', 'Betha']\n",
    "\n",
    "\n",
    "for i in range(0,7):\n",
    "    plt.figure(i)\n",
    "    #plt.title('Kernel for '+ band[i])\n",
    "    plt.imshow(Ktrain[i],cmap= plt.cm.get_cmap('OrRd'))\n",
    "    #plt.savefig('DEAP_Figures/Kernel_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Kernel_train,cmap= plt.cm.get_cmap('OrRd'))\n",
    "#plt.savefig('DEAP_Figures/Final_Kernel')\n",
    "print(weights_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensayo=np.matmul(ytrain2,ytrain2.T)\n",
    "plt.imshow(ensayo,cmap= plt.cm.get_cmap('OrRd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "x=np.arange(0,496)\n",
    "y=np.arange(0,40)\n",
    "X,Y= np.meshgrid(x,y)\n",
    "z=Y*X\n",
    "print(Feature_MSC_Matrix_C2[0,0].shape)\n",
    "fig= plt.figure()\n",
    "ax= fig.gca(projection='3d')\n",
    "ax.contour(X,Y,Feature_MSC_Matrix_C2[0,0,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
