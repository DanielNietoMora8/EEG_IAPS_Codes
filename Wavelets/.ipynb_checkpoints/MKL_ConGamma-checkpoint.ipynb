{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excombatants Classification using wavelets and MKL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#LibrerÃ­as Necesarias Para el CÃ³digo organizadas por tipo de llamado y orden alfabÃ©tico.\n",
    "import csv\n",
    "#import h5py\n",
    "import scipy\n",
    "import statistics\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import scipy.io as sio\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "from scipy import signal\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import svm\n",
    "from ckaweightedMKL1 import ckaweightedK\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#from unipath import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGA DE LAS CARACTRERÃSTICAS Y LAS ETIQUETAS BINARIZADAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf) #Imprime todos los valores de los arrays, sirve para visualizar mejor los datos\n",
    "\n",
    "\n",
    "import pickle\n",
    "File= open('Wavelets_Excombatants/y.pckl', 'rb')\n",
    "label_matrix= pickle.load(File)\n",
    "File.close()\n",
    "\n",
    "num_valences= 3\n",
    "num_rois = 8\n",
    "num_channels= 62\n",
    "num_trials= 50\n",
    "#To assess the performance of the C in each emotion, later to evaluate is not necessary.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Created functions to perform MKL clasiffication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MixKer(K,eta):\n",
    "    Kn= np.zeros_like((K[1]))\n",
    "    for i in range(len(eta)):\n",
    "        Kn= Kn + eta[i]*(K[i])\n",
    "    return(Kn)\n",
    "\n",
    "def KerRBF(X):\n",
    "    d= spatial.distance.pdist(X)\n",
    "    gamma= 1/(X.shape[1]*X.var())\n",
    "    K= -spatial.distance.squareform(d)*gamma\n",
    "    K= np.exp(K)\n",
    "    return(K)\n",
    "    \n",
    "def KerLin(X):\n",
    "    K = np.matmul(X,X.T)\n",
    "    return(K)\n",
    "\n",
    "def graficar(F1_test,Subjects,emocion,save):  \n",
    "    Bandas=np.arange(1,5)\n",
    "    Subject= np.arange(1,Subjects+1)\n",
    "    contador=1\n",
    "   \n",
    "\n",
    "    plt.figure(contador,figsize=(6,5))\n",
    "    plt.title('MKL Emocion: ')\n",
    "    plt.bar(Subject, F1_test[:], align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan'])\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('Frequency Band')\n",
    "    plt.ylabel('F1 Score')\n",
    "    if save== 'y':\n",
    "        plt.savefig('FiguresMKL_5/'+'C2_Improved')\n",
    "    plt.show()\n",
    "    contador+=1\n",
    "    \n",
    "    \n",
    "def svc_param_selection(y, nfolds,Kernel_train_Wavelets):\n",
    "    Cs = 1.**np.arange(-1,1)\n",
    "    #gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C':Cs}\n",
    "    clf=svm.SVC(kernel='precomputed',class_weight = 'balanced')\n",
    "    clf.fit(Kernel_train_Wavelets,y)\n",
    "    grid_search = GridSearchCV(clf,param_grid,  cv=nfolds)\n",
    "    grid_search.fit(Kernel_train, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n",
    "\n",
    "def Moda(N_Emociones,Subjects,Best_C_Matrix):\n",
    "    Mode_C=np.zeros([N_Emociones])\n",
    "    Mode_aux=np.zeros([Subjects,N_Emociones])\n",
    "    Mode_aux2=np.zeros([Subjects,N_Emociones])\n",
    "    for emo in range(0,N_Emociones):\n",
    "        print('Emocion: ',emo)\n",
    "        for sub in range(Subjects):\n",
    " \n",
    "            a= Best_C_Matrix[sub,emo,:]\n",
    "            a=a.tolist()\n",
    "            Mode_aux[sub,emo]= max(a,key=a.count)           \n",
    "      \n",
    "        try:\n",
    "            c= Mode_aux[:,emo]\n",
    "            c=c.tolist()\n",
    "            Mode_C[emo]=max(c,key=c.count)\n",
    "        except:\n",
    "            print('Nada3')\n",
    "    \n",
    "    print(' Mode Valence: ',Mode_C[0],'\\n Mode Arousal: ',Mode_C[1],'\\n Mode Dominance: ',Mode_C[2], '\\n Mode Liking: ',Mode_C[3])\n",
    "    return Mode_C\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM RBF Multiple Kernel Learning MKL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 5 bands: \n",
    "### Here it was performed a classification for each valence and it was combined the ROIs and statistical features in a single dimension, keeping the bands dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 50, 64)\n",
      "Analizando Wavelet: sym8 Valencia : 0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [1. 1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [-1. -1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.88\n",
      "Analizando Wavelet: sym8 Valencia : 1\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.84\n",
      "Analizando Wavelet: sym8 Valencia : 2\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.98\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3, 25, 5)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "SE GUARDÃ“ EL ARCHIVO sym8_valences_bands_easy_MKL\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 5\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs_2021/Features_Stats_Wavelets_'+wave_name[wave]+'_valences_bands'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds,Valences])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences])\n",
    "    F1_test = np.zeros([Valences])\n",
    "    ACC_test = np.zeros([Valences])\n",
    "    STD_F1_test = np.zeros([Valences])\n",
    "    STD_ACC_test = np.zeros([Valences])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([Valences,N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence)) \n",
    "\n",
    "        for band in range(0,N_Band):\n",
    "            scaler = MinMaxScaler()\n",
    "            K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[valence,band,:,:]))\n",
    "            K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "            K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[valence,1,:,:])):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "            y_test.append(ytest)\n",
    "\n",
    "            #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "        #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "            Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "            Ktrain =  K[:,train_index,:]\n",
    "            Ktrain = Ktrain[:,:,train_index]\n",
    "            Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "            Ktest = K[:,test_index,:]\n",
    "            Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "        #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "            #earlystop = EarlyStopping(\n",
    "            #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "            #            patience=5,     #max number of acceptable negative steps\n",
    "            #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "            #            metric='auc',   #the metric we monitor\n",
    "            #            )\n",
    "\n",
    "            #scheduler = ReduceOnWorsening()\n",
    "\n",
    "            #mkl = GRAM(\n",
    "            #max_iter=1000,          \n",
    "            #learning_rate=.01,      \n",
    "            #callbacks=[earlystop],\n",
    "            #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "            #print(mkl)\n",
    "            #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "        #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "            clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "            weights_train = clf_Linear_Easy.weights\n",
    "            #print(weights_train)\n",
    "\n",
    "            #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "            #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "            #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "            #aux=np.ones(len(weights_train))\n",
    "            #weights_train = aux-weights_train\n",
    "            #print(weights_train)\n",
    "            weights[valence,fold]=weights_train\n",
    "            Kernel_train= MixKer(Ktrain,weights_train)\n",
    "            Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "        #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\"\n",
    "            clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "            ##print(K_average)\n",
    "            #print ('training EasyMKL...', end='')\n",
    "            clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "            #print(K_Linear_average)\n",
    "            Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "            Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "            \"\"\"\n",
    "        #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "            #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            #Median= statistics.median(Distances)\n",
    "            Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "            SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "            SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "            F1_test_fold[fold,valence] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,valence]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold,valence],\"F1:\",F1_test_fold[fold,valence],\"C:\",Parameters_grid['C'])\n",
    "            #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "            fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test[valence] = np.mean(F1_test_fold[:,valence])\n",
    "        ACC_test[valence]= np.mean(ACC_test_fold[:,valence])\n",
    "        STD_F1_test[valence] = np.std(F1_test_fold[:,valence])\n",
    "        STD_ACC_test[valence] = np.std(ACC_test_fold[:,valence])\n",
    "        print(ACC_test[valence])\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valences_bands_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 8 Rois: \n",
    "### Here it was performed a classification for each valence and it was combined bands and statistical features in a single dimension, keeping the rois dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 50, 40)\n",
      "Analizando Wavelet: sym8 Valencia : 0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.8\n",
      "Analizando Wavelet: sym8 Valencia : 1\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [-1.  1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.72\n",
      "Analizando Wavelet: sym8 Valencia : 2\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "y_test: [-1. -1.] SVM: [1. 1.] ACC: 0.0 F1: 0.0 C: 1.0\n",
      "INICIO TEST\n",
      "0.66\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3, 25, 8)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "SE GUARDÃ“ EL ARCHIVO sym8_valences_rois_easy_MKL\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 8\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs_2021/Features_Stats_Wavelets_'+wave_name[wave]+'_valences_rois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds,Valences])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences])\n",
    "    F1_test = np.zeros([Valences])\n",
    "    ACC_test = np.zeros([Valences])\n",
    "    STD_F1_test = np.zeros([Valences])\n",
    "    STD_ACC_test = np.zeros([Valences])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([Valences,N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence)) \n",
    "\n",
    "        for band in range(0,N_Band):\n",
    "            scaler = MinMaxScaler()\n",
    "            K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[valence,band,:,:]))\n",
    "            K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "            K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[valence,1,:,:])):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "            y_test.append(ytest)\n",
    "\n",
    "            #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "        #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "            Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "            Ktrain =  K[:,train_index,:]\n",
    "            Ktrain = Ktrain[:,:,train_index]\n",
    "            Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "            Ktest = K[:,test_index,:]\n",
    "            Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "        #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "            #earlystop = EarlyStopping(\n",
    "            #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "            #            patience=5,     #max number of acceptable negative steps\n",
    "            #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "            #            metric='auc',   #the metric we monitor\n",
    "            #            )\n",
    "\n",
    "            #scheduler = ReduceOnWorsening()\n",
    "\n",
    "            #mkl = GRAM(\n",
    "            #max_iter=1000,          \n",
    "            #learning_rate=.01,      \n",
    "            #callbacks=[earlystop],\n",
    "            #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "            #print(mkl)\n",
    "            #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "        #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "            clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "            weights_train = clf_Linear_Easy.weights\n",
    "            #print(weights_train)\n",
    "\n",
    "            #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "            #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "            #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "            #aux=np.ones(len(weights_train))\n",
    "            #weights_train = aux-weights_train\n",
    "            #print(weights_train)\n",
    "            weights[valence,fold]=weights_train\n",
    "            Kernel_train= MixKer(Ktrain,weights_train)\n",
    "            Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "        #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\"\n",
    "            clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "            ##print(K_average)\n",
    "            #print ('training EasyMKL...', end='')\n",
    "            clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "            #print(K_Linear_average)\n",
    "            Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "            Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "            \"\"\"\n",
    "        #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "            #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            #Median= statistics.median(Distances)\n",
    "            Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "            SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "            SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "            F1_test_fold[fold,valence] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,valence]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold,valence],\"F1:\",F1_test_fold[fold,valence],\"C:\",Parameters_grid['C'])\n",
    "            #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "            fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test[valence] = np.mean(F1_test_fold[:,valence])\n",
    "        ACC_test[valence]= np.mean(ACC_test_fold[:,valence])\n",
    "        STD_F1_test[valence] = np.std(F1_test_fold[:,valence])\n",
    "        STD_ACC_test[valence] = np.std(ACC_test_fold[:,valence])\n",
    "        print(ACC_test[valence])\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valences_rois_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 40 bands: \n",
    "### Here it was performed a classification for each valence and it was combined the bands and ROIs in a single dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 40, 50, 8)\n",
      "Analizando Wavelet: sym8 Valencia : 0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [ 1. -1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [-1.  1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [ 1. -1.] SVM: [-1.  1.] ACC: 0.0 F1: 0.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "INICIO TEST\n",
      "0.9333333333333332\n",
      "Analizando Wavelet: sym8 Valencia : 1\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "INICIO TEST\n",
      "0.9866666666666666\n",
      "Analizando Wavelet: sym8 Valencia : 2\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [1. 1.] SVM: [1. 1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [ 1. -1.] SVM: [1. 1.] ACC: 0.5 F1: 0.6666666666666666\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "y_test: [-1. -1.] SVM: [-1. -1.] ACC: 1.0 F1: 1.0\n",
      "INICIO TEST\n",
      "0.9866666666666666\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3, 25, 40)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "(3,)\n",
      "Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\n",
      "SE GUARDÃ“ EL ARCHIVO sym8_valences_bandrois_easy_MKL\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 40\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs_2021/Features_Stats_Wavelets_'+wave_name[wave]+'_valences_bandrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds,Valences])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences])\n",
    "    F1_test = np.zeros([Valences])\n",
    "    ACC_test = np.zeros([Valences])\n",
    "    STD_F1_test = np.zeros([Valences])\n",
    "    STD_ACC_test = np.zeros([Valences])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([Valences,N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence)) \n",
    "\n",
    "        for band in range(0,N_Band):\n",
    "            scaler = MinMaxScaler()\n",
    "            K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[valence,band,:,:]))\n",
    "            K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "            K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[valence,1,:,:]),label_matrix):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "            ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "            y_test.append(ytest)\n",
    "\n",
    "            #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "        #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "            Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "            Ktrain =  K[:,train_index,:]\n",
    "            Ktrain = Ktrain[:,:,train_index]\n",
    "            Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "            Ktest = K[:,test_index,:]\n",
    "            Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "        #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "            #earlystop = EarlyStopping(\n",
    "            #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "            #            patience=5,     #max number of acceptable negative steps\n",
    "            #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "            #            metric='auc',   #the metric we monitor\n",
    "            #            )\n",
    "\n",
    "            #scheduler = ReduceOnWorsening()\n",
    "\n",
    "            #mkl = GRAM(\n",
    "            #max_iter=1000,          \n",
    "            #learning_rate=.01,      \n",
    "            #callbacks=[earlystop],\n",
    "            #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "            #print(mkl)\n",
    "            #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "        #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "            clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "            weights_train = clf_Linear_Easy.weights\n",
    "            #print(weights_train)\n",
    "\n",
    "            #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "            #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "            #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "            #aux=np.ones(len(weights_train))\n",
    "            #weights_train = aux-weights_train\n",
    "            #print(weights_train)\n",
    "            weights[valence,fold]=weights_train\n",
    "            Kernel_train= MixKer(Ktrain,weights_train)\n",
    "            Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "        #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\"\n",
    "            clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "            ##print(K_average)\n",
    "            #print ('training EasyMKL...', end='')\n",
    "            clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "            #print(K_Linear_average)\n",
    "            Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "            Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "            \"\"\"\n",
    "        #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "            #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            #Median= statistics.median(Distances)\n",
    "            Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "            SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "            SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "            F1_test_fold[fold,valence] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,valence]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold,valence],\"F1:\",F1_test_fold[fold,valence])\n",
    "            #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "            fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test[valence] = np.mean(F1_test_fold[:,valence])\n",
    "        ACC_test[valence]= np.mean(ACC_test_fold[:,valence])\n",
    "        STD_F1_test[valence] = np.std(F1_test_fold[:,valence])\n",
    "        STD_ACC_test[valence] = np.std(ACC_test_fold[:,valence])\n",
    "        print(F1_test[valence])\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valences_bandrois_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 5 bands and no-valences: \n",
    "### Here it was performed a classification mixing the Valences, ROIs and statistical features in a single dimension, keeping the bands dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 50, 192)\n",
      "Analizando Wavelet: sym8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ae1d70eadb6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_Band\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerRBF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFeatures_Stats_Wavelets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 5\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs_2021/Features_Stats_Wavelets_'+wave_name[wave]+'_valencesrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave]) \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        scaler = MinMaxScaler()\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "        K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "        K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        #Median= statistics.median(Distances)\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test = np.mean(F1_test_fold[:])\n",
    "        ACC_test= np.mean(ACC_test_fold[:])\n",
    "        STD_F1_test = np.std(F1_test_fold[:])\n",
    "        STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        print(ACC_test)\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valencesrois_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 8 Rois and no-valences: \n",
    "### Here it was performed a classification mixing the Valences, Bands and statistical features in a single dimension, keeping the Rois dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 8\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs_2021/Features_Stats_Wavelets_'+wave_name[wave]+'_valencesbands'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave]) \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        scaler = MinMaxScaler()\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "        K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "        K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        #Median= statistics.median(Distances)\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test = np.mean(F1_test_fold[:])\n",
    "        ACC_test= np.mean(ACC_test_fold[:])\n",
    "        STD_F1_test = np.std(F1_test_fold[:])\n",
    "        STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        print(ACC_test)\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valencesbands_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 40 bands and no-valences: \n",
    "### Here it was performed a classification mixing the Valences, ROIs and statistical features in a single dimension, keeping the bands dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Valences=3\n",
    "CrossVal= KFold(n_splits=25,shuffle=False)\n",
    "N_Band= 40\n",
    "N_Trials= 50\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs_2021/Features_Stats_Wavelets_'+wave_name[wave]+'_bandrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave]) \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        scaler = MinMaxScaler()\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "        K[band,:,:] = scaler.fit_transform(K[band,:,:])\n",
    "        K[band,:,:] = normalize(K[band,:,:])\n",
    "\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        #Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[valence,band,train_index,:]), (Features_Stats_Wavelets[valence,band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        #Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        #Median= statistics.median(Distances)\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Kernel_test)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test = np.mean(F1_test_fold[:])\n",
    "        ACC_test= np.mean(ACC_test_fold[:])\n",
    "        STD_F1_test = np.std(F1_test_fold[:])\n",
    "        STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        print(ACC_test)\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_bandrois_easy_MKL'\n",
    "    #Pickle Save F1 Score\n",
    "    path_save= \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open(path_save+'Weights_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Weights_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ACC_test)\n",
    "print(STD_F1_test)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNUSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "CrossVal= LeaveOneOut()\n",
    "N_Band= 5\n",
    "N_Trials= 50\n",
    "N_Rois = 8\n",
    "C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_valencesrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    \n",
    "    SVM_Prediction_test=np.zeros([N_folds])\n",
    "    y_test = np.zeros([N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "  \n",
    "    print('Analizando Wavelet: '+wave_name[wave]+' Valencia : ') \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        y_test[fold] = ytest\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test[fold] = ytest\n",
    "\n",
    "        Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[band,train_index,:]), (Features_Stats_Wavelets[band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        Median= statistics.median(Distances)\n",
    "        #Gamma= 1/(2*(Median**2))\n",
    "        Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Gamma,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',gamma=Gamma,C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test[fold]= SVM_Classifier.predict(Kernel_test)\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    F1_test = f1_score(y_test[:],SVM_Prediction_test[:])\n",
    "    ACC_test= acc(y_test[:],SVM_Prediction_test[:])\n",
    "    print(F1_test)\n",
    "    #graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_valencesrois_easy'\n",
    "    #Pickle Save F1 Score\n",
    "    import pickle\n",
    "    file= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "CrossVal= LeaveOneOut()\n",
    "N_Band= 40\n",
    "N_Trials= 50\n",
    "C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,Subjects,Best_C_Matrix)\n",
    "N_cs = len(C)\n",
    "\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5):\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wave_name[wave]+'_bandrois'+'.pckl', 'rb')\n",
    "    Features_Stats_Wavelets = pickle.load(File)\n",
    "    File.close()\n",
    "    N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,:,:]))\n",
    "    \n",
    "    SVM_Prediction_test=np.zeros([N_folds])\n",
    "    y_test = np.zeros([N_folds])\n",
    "    K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "    weights=np.zeros([N_folds,N_Band])\n",
    "\n",
    "    print(Features_Stats_Wavelets.shape)\n",
    "    \n",
    "   \n",
    "    print('Analizando Wavelet: '+wave_name[wave]) \n",
    "\n",
    "    for band in range(0,N_Band):\n",
    "        K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[band,:,:]))\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        y_test[fold] = ytest\n",
    "        ytrainMKL, ytestMKL = label_matrix[train_index], label_matrix[test_index]\n",
    "        ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "        y_test[fold] = ytest\n",
    "\n",
    "        Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[band,train_index,:]), (Features_Stats_Wavelets[band,test_index,:])\n",
    "\n",
    "    #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "        Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "        Ktrain =  K[:,train_index,:]\n",
    "        Ktrain = Ktrain[:,:,train_index]\n",
    "        Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "        Ktest = K[:,test_index,:]\n",
    "        Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "\n",
    "    #--- Multiple Kernel Learning GRAM---------------------------------------------------------------------\n",
    "\n",
    "        #earlystop = EarlyStopping(\n",
    "        #            Ktrain, ytrain,      #validation data, KL is a validation kernels list\n",
    "        #            patience=5,     #max number of acceptable negative steps\n",
    "        #            cooldown=1,     #how ofter we run a measurement, 1= every optimization step\n",
    "        #            metric='auc',   #the metric we monitor\n",
    "        #            )\n",
    "\n",
    "        #scheduler = ReduceOnWorsening()\n",
    "\n",
    "        #mkl = GRAM(\n",
    "        #max_iter=1000,          \n",
    "        #learning_rate=.01,      \n",
    "        #callbacks=[earlystop],\n",
    "        #scheduler=ReduceOnWorsening()).fit(Ktrain, ytrain)\n",
    "        #print(mkl)\n",
    "        #mkl.predict(Ktest)\n",
    "\n",
    "\n",
    "    #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "        clf_Linear_Easy = EasyMKL(lam=1).fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #clf_Linear_Easy = AverageMKL().fit(Ktrain,ytrain)\n",
    "        weights_train = clf_Linear_Easy.weights\n",
    "        #print(weights_train)\n",
    "\n",
    "        #weights_train = ckaweightedK(Ktrain,ytrain)\n",
    "\n",
    "        #weights_train = np.random.uniform(low=0.0, high=1.0, size=N_Band)\n",
    "        #weights_train = weights_train/np.sum(weights_train)\n",
    "\n",
    "        #aux=np.ones(len(weights_train))\n",
    "        #weights_train = aux-weights_train\n",
    "        #print(weights_train)\n",
    "        weights[fold]=weights_train\n",
    "        Kernel_train= MixKer(Ktrain,weights_train)\n",
    "        Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "    #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "        \"\"\"\"\n",
    "        clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "        ##print(K_average)\n",
    "        #print ('training EasyMKL...', end='')\n",
    "        clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "        #print ('done')\n",
    "        #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "        K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "        #print(K_Linear_average)\n",
    "        Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "        Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "        \"\"\"\n",
    "    #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "        Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        Median= statistics.median(Distances)\n",
    "        Parameters_grid = svc_param_selection(ytrain,5,Gamma,Kernel_train)\n",
    "        SVM_Classifier= svm.SVC(kernel='precomputed',gamma=Gamma,C=Parameters_grid['C'],class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "        SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "        SVM_Prediction_test[fold]= SVM_Classifier.predict(Kernel_test)\n",
    "        #F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "\n",
    "        fold+=1\n",
    "\n",
    "    #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    F1_test = f1_score(y_test[:],SVM_Prediction_test[:])\n",
    "    ACC_test = acc(y_test[:],SVM_Prediction_test[:])\n",
    "    print(F1_test)\n",
    "#graficar(F1_test,Subjects,emocion)\n",
    "    \n",
    "    wav= wave_name[wave]+'_bandrois_easy'\n",
    "    #Pickle Save F1 Score\n",
    "    import pickle\n",
    "    file= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/F1_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/ACC_Score_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle Save Weights\n",
    "    file= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'wb')\n",
    "    pickle.dump(weights,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/Weights_'+wav+'_MKL.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == weights).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File= open('Wavelets_Results/F1_Score_'+'bior3.3_sparse'+'_MKL.pckl', 'rb')\n",
    "F1_test = pickle.load(File)\n",
    "File.close()\n",
    "print(F1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_test.tofile('Test_5\\F1_Test_KRBF_C3_MKL_Improved'+'.txt')\n",
    "#Best_C_Matrix.tofile('Test_5\\Best_C_Matrix_C2_MKL'+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRÃFICA DEL F1_SCORE PARA CADA SUJETO EN CADA BANDA Y PARA CADA C \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------\n",
    "Subjects= 32\n",
    "CrossVal= LeaveOneOut()\n",
    "N_folds= CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[1,1,:,:]))\n",
    "N_Band= 6\n",
    "N_Trials= 40\n",
    "N_Emociones=4\n",
    "C = 2.**np.arange(-15,19)\n",
    "N_cs = len(C)\n",
    "Best_C_Matrix=np.zeros([Subjects,N_Emociones,N_folds])\n",
    "F1_train = np.zeros([Subjects,N_Emociones,N_folds,N_cs])\n",
    "F1_test = np.zeros([Subjects,N_Emociones])\n",
    "SVM_Prediction_test=np.zeros([Subjects,N_Emociones,N_folds])\n",
    "y_test = np.zeros([Subjects,N_folds])\n",
    "K = np.zeros([N_Band,N_Trials,N_Trials])\n",
    "\n",
    "#---Iterations for each Emotion and subject--------------------------------------------------------------------------\n",
    "\n",
    "for emo in range(N_Emociones):\n",
    "    for sub in range(Subjects):\n",
    "        print('AnÃ¡lisis Sujeto: ',sub, 'EmociÃ³n: ',emo)\n",
    "        if (sub==26 and emo==2):\n",
    "            sub+=1\n",
    "            \n",
    "        for band in range(0,N_Band):\n",
    "            K[band,:,:] = KerRBF(np.squeeze(Features_Stats_Wavelets[sub,band,:,:]))\n",
    "\n",
    "        fold = 0\n",
    "        emocion=emo\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[sub,1,:,:])):\n",
    "            ytrain, ytest = label_threshold_matrix_5[sub,train_index,emocion], label_threshold_matrix_5[sub,test_index,emocion]\n",
    "            y_test[sub,fold] = ytest\n",
    "            ytrainMKL, ytestMKL = label_matrix[sub,train_index,emocion], label_matrix[sub,test_index,emocion]\n",
    "            ytrain2=np.expand_dims(ytrainMKL,axis=1)\n",
    "            y_test[sub,fold] = ytest\n",
    "\n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[sub,band,train_index,:]), (Features_Stats_Wavelets[sub,band,test_index,:])\n",
    "\n",
    "        #---Definition of kernels variables for the multiple kernel learning--------------------------------------------------------\n",
    "\n",
    "            Ktrain = np.zeros([N_Band,len(train_index),len(train_index)])\n",
    "            Ktrain =  K[:,train_index,:]\n",
    "            Ktrain = Ktrain[:,:,train_index]\n",
    "            Ktest = np.zeros([N_Band,len(test_index),len(train_index)])\n",
    "            Ktest = K[:,test_index,:]\n",
    "            Ktest = Ktest[:,:,train_index]\n",
    "\n",
    "        #---Multiple Kernel Learning Custom Functions---------------------------------------------------------------------------\n",
    "\n",
    "            #print(Ktrain.shape, ytrain2.shape)\n",
    "            weights_train = ckaweightedK(Ktrain,ytrain2)\n",
    "            #print(weights_train)\n",
    "            Kernel_train= MixKer(Ktrain,weights_train)\n",
    "            Kernel_test= MixKer(Ktest,weights_train)\n",
    "\n",
    "        #---Multiple Kernel Learning------------------------------------------------------------------------------------------------\n",
    "            \"\"\"\"\n",
    "            clf_Linear_Average = AverageMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Average.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_average = clf_Linear_Average.ker_matrix\t#the combined kernel matrix\n",
    "            ##print(K_average)\n",
    "            #print ('training EasyMKL...', end='')\n",
    "            clf_Linear_Easy = EasyMKL().fit(Ktrain,ytrain)\t#a wrapper for averaging kernels\n",
    "            #print ('done')\n",
    "            #print(clf_Linear_Easy.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "            K_Linear_easy = clf_Linear_Easy.ker_matrix\t#the combined kernel matrix\n",
    "            #print(K_Linear_average)\n",
    "            Ktrain = MixKer(Ktrain,clf_Linear_Easy.weights)\n",
    "            Ktest = MixKer(Ktest,clf_Linear_Easy.weights)\n",
    "            \"\"\"\n",
    "        #---F1-score evaluation for training set------------------------------------------------------------------------------------\n",
    "\n",
    "            Best_C= -10000\n",
    "            Best_F1=0\n",
    "            for c in range(len(C)):\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= statistics.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                SVM_Classifier= svm.SVC(kernel='precomputed',C=C[c])\n",
    "                SVM_Classifier.fit(Kernel_train,ytrain)\n",
    "                SVM_Prediction_train= SVM_Classifier.predict(Kernel_train)\n",
    "                SVM_Prediction_test[sub,emo,fold]= SVM_Classifier.predict(Kernel_test)\n",
    "                F1_train[sub,emo,fold,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "                if F1_train[sub,emo,fold,c]>Best_F1:\n",
    "                    Best_C_Matrix[valence,fold]=C[c]\n",
    "                    Best_C= C[c]\n",
    "                    Best_F1=F1_train[valence,fold,c]\n",
    "            fold+=1\n",
    "\n",
    "\n",
    "\n",
    "        #---F1-score evaluation for test set---------------------------------------------------------------------------------------\n",
    "\n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        F1_test[sub,emo] = f1_score(y_test[sub,:],SVM_Prediction_test[sub,emo,:],average='macro')\n",
    "        #print(F1_test[sub,band,c])\n",
    "        #time.sleep(4)\n",
    "    graficar(F1_test,Subjects,emocion)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "graficar(F1_test,Subjects,3)\n",
    "Moda(N_Emociones,Subjects,Best_C_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1_test.tofile('Test\\F1_Test_Customlib_RBF_Lineal_C3_'+Emocion[emocion]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band=['Theta','Low Alpha', 'High Alpha', 'Alha', 'Betha']\n",
    "\n",
    "\n",
    "for i in range(0,7):\n",
    "    plt.figure(i)\n",
    "    #plt.title('Kernel for '+ band[i])\n",
    "    plt.imshow(Ktrain[i],cmap= plt.cm.get_cmap('OrRd'))\n",
    "    #plt.savefig('DEAP_Figures/Kernel_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Kernel_train,cmap= plt.cm.get_cmap('OrRd'))\n",
    "#plt.savefig('DEAP_Figures/Final_Kernel')\n",
    "print(weights_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensayo=np.matmul(ytrain2,ytrain2.T)\n",
    "plt.imshow(ensayo,cmap= plt.cm.get_cmap('OrRd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "x=np.arange(0,496)\n",
    "y=np.arange(0,40)\n",
    "X,Y= np.meshgrid(x,y)\n",
    "z=Y*X\n",
    "print(Feature_MSC_Matrix_C2[0,0].shape)\n",
    "fig= plt.figure()\n",
    "ax= fig.gca(projection='3d')\n",
    "ax.contour(X,Y,Feature_MSC_Matrix_C2[0,0,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
