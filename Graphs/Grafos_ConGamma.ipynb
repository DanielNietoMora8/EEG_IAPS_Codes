{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICACIÃ“N DE EMOCIONES UTILIZANDO BASE DE DATOS DE VALENCIA CONTEXTUAL\n",
    "\n",
    "## OrganizaciÃ³n de las bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3, 5, 5, 5) (50,)\n"
     ]
    }
   ],
   "source": [
    "#LibrerÃ­as Necesarias Para el CÃ³digo organizadas por tipo de llamado y orden alfabÃ©tico.\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pickle\n",
    "import pywt\n",
    "from scipy import signal\n",
    "from sklearn import svm\n",
    "import statistics as stats\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "file= open('Excombatants_Data/X.pckl', 'rb')\n",
    "EEG = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file= open('Excombatants_Data/y.pckl', 'rb')\n",
    "label_matrix = pickle.load(file)\n",
    "file.close()\n",
    "print(EEG[0].shape,label_matrix.shape)\n",
    "\n",
    "num_valences= 3\n",
    "num_channels= 62\n",
    "num_trials= 50\n",
    "num_thresholds = 5\n",
    "\n",
    "#[trials, valences, bands, trhesholds, Graph_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(50, 3, 5, 5, 5)\n",
      "(3, 50, 5, 5, 5)\n",
      "(3, 5, 50, 5, 5)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "new = np.array((EEG[0]))\n",
    "print(abs(np.sum(new - EEG[0])))\n",
    "print(new.shape)\n",
    "new = np.swapaxes(new, 0,1)\n",
    "print(new.shape)\n",
    "new = np.swapaxes(new, 1,2)\n",
    "print(new.shape)\n",
    "print(new[0,0,0,0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function characterization is used to create region of interest (ROI) clustering channels by indexes, then \n",
    "# we return several vectors according to the experiment, i.e. if the experiment has valences or not, if it will\n",
    "# combine information of rois or bands or even both with features, etc.\n",
    "\n",
    "\n",
    "def characterization(Filtered_Data,num_valences,num_trials,num_channels,wave,kind):\n",
    "    #Wavelet transform calculation, it is specified the dataset to transform, wavelet type and decomposition level\n",
    "    DWT_values= pywt.wavedec(Filtered_Data,wave,mode='sp1', level=4)\n",
    "    DWT_values = DWT_values[0:5]\n",
    "    len_D = len(DWT_values)\n",
    "    \n",
    "    ROI_1 = [0, 1, 2, 3, 4, 8, 9, 10, 18]\n",
    "    ROI_2 = [5, 6, 7, 14, 15, 16, 17]\n",
    "    ROI_3 = [11, 12, 13, 19, 20, 21, 22]\n",
    "    ROI_4 = [23, 24, 32, 33, 41, 42, 50]\n",
    "    ROI_5 = [30, 31, 39, 40, 48, 49, 56]\n",
    "    ROI_6 = [25, 26, 27, 28, 29, 34, 35, 36, 37, 38]\n",
    "    ROI_7 = [43, 44, 45, 46, 47, 51, 52, 53, 54, 55]\n",
    "    ROI_8 = [57, 58, 59, 60, 61]\n",
    "    ROIS = [ROI_1, ROI_2, ROI_3, ROI_4, ROI_5, ROI_6, ROI_7, ROI_8] #vector of regions of interest, each index is a channel\n",
    "    \n",
    "    ROI_ALL=[[]]*8\n",
    "    for i in range(8):\n",
    "        ROI_ALL[i] = [[]]*(len_D)\n",
    "    #Features_Wavelet store the data transform dividing into EEG Rhythms\n",
    "    Features_Stats=np.zeros([num_valences,len(DWT_values),num_trials,len(ROIS),8])\n",
    "    #print(len(ROI_ALL))\n",
    "    for roi in range(len(ROIS)):\n",
    "        for band in range(len(DWT_values)):\n",
    "            ROI_ALL[roi][band]=(np.mean(DWT_values[band][:,:,ROIS[roi],:],axis=2)) # we compute the mean of all channels of the same ROI\n",
    "            #Statistical Features\n",
    "            Features_Stats[:,band,:,roi,0] = np.max(ROI_ALL[roi][band],axis=2) # max value feature\n",
    "            Features_Stats[:,band,:,roi,1] = np.min(ROI_ALL[roi][band],axis=2) # min value feature\n",
    "            Features_Stats[:,band,:,roi,2] = np.mean(ROI_ALL[roi][band],axis=2) # mean\n",
    "            Features_Stats[:,band,:,roi,3] = np.var(ROI_ALL[roi][band],axis=2) # variance\n",
    "            Features_Stats[:,band,:,roi,4] = np.std(ROI_ALL[roi][band],axis=2) # standard deviation\n",
    "            Features_Stats[:,band,:,roi,5] = np.median(ROI_ALL[roi][band],axis=2) # median\n",
    "            Features_Stats[:,band,:,roi,6] = kurtosis(ROI_ALL[roi][band],axis=2) # kurtosis\n",
    "            Features_Stats[:,band,:,roi,7] = skew(ROI_ALL[roi][band],axis=2) #skewness\n",
    "            \n",
    "    #in this part, we organize the dimensions to later take to the classifier\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats,1,2)\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats_ROI,2,3)\n",
    "    Features_Stats_ROI = Features_Stats_ROI.reshape(num_valences,num_trials,len_D*len(ROIS),8)\n",
    "    Features_Stats_ROI = np.swapaxes(Features_Stats_ROI,1,2)\n",
    "    Features_Stats_Bands = Features_Stats.reshape(num_valences,len_D,num_trials,len(ROIS)*8)\n",
    "    Features_Stats_Rois = Features_Stats.reshape(num_valences,len(ROIS),num_trials,len_D*8)\n",
    "    \n",
    "    Features_Stats_ValenceBands = np.swapaxes(Features_Stats,0,1)\n",
    "    Features_Stats_ValenceBands = np.swapaxes(Features_Stats_ValenceBands,1,2)\n",
    "    Features_Stats_ValenceBands = Features_Stats_ValenceBands.reshape(len_D,num_trials,num_valences,len(ROIS)*8)\n",
    "    Features_Stats_ValenceBands = Features_Stats_ValenceBands.reshape(len_D,num_trials,num_valences*len(ROIS)*8)\n",
    "    \n",
    "    Features_Stats_All = np.swapaxes(Features_Stats_ValenceBands,0,1)\n",
    "    #Features_Stats_ALL = np.swapaxes(Features_Stats_ALL,2,3)\n",
    "    Features_Stats_All = Features_Stats_All.reshape(num_trials,num_valences*len(ROIS)*8*len(DWT_values))\n",
    "    Features_Stats_ValencesRois = np.swapaxes(Features_Stats,0,2)\n",
    "    Features_Stats_ValencesRois = Features_Stats_ValencesRois.reshape(num_trials,len(DWT_values),num_valences*len(ROIS)*8)\n",
    "    Features_Stats_ValencesRois = np.swapaxes(Features_Stats_ValencesRois,0,1)\n",
    "    \n",
    "    Features_Stats_Valencesbands = np.swapaxes(Features_Stats,0,2)\n",
    "    Features_Stats_Valencesbands = Features_Stats_Valencesbands.reshape(num_trials,len(ROIS),num_valences*len(DWT_values)*8)\n",
    "    Features_Stats_Valencesbands = np.swapaxes(Features_Stats_Valencesbands,0,1)\n",
    "  \n",
    "    #\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats,1,2)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,2,3)\n",
    "    Features_Stats_Valences = Features_Stats_Valences.reshape(num_valences,num_trials,len_D*len(ROIS),8)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,0,1)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,1,2)\n",
    "    Features_Stats_Valences = Features_Stats_Valences.reshape(num_trials,len_D*len(ROIS),num_valences*8)\n",
    "    Features_Stats_Valences = np.swapaxes(Features_Stats_Valences,0,1)\n",
    "    \n",
    "    Features_Stats_original = Features_Stats\n",
    "    Features_Stats=Features_Stats.reshape(num_valences,len_D,num_trials,64)\n",
    "    \n",
    "    # Return the vector according to the input    \n",
    "    if kind == 'complete' or kind == 0:\n",
    "        return Features_Stats\n",
    "    elif kind == 'ROI' or kind ==1:\n",
    "        return Features_Stats_ROI\n",
    "    elif kind == 'all' or kind ==2:\n",
    "        return Features_Stats_All\n",
    "    elif kind == \"valroi\" or kind ==3:\n",
    "        return Features_Stats_ValencesRois\n",
    "    elif kind == \"valences\" or kind ==4:\n",
    "        return Features_Stats_Valences\n",
    "    elif kind == \"original\" or kind == 5:\n",
    "        return Features_Stats_original\n",
    "    elif kind == 'bands' or kind ==6:\n",
    "        return Features_Stats_Bands\n",
    "    elif kind == \"rois\" or kind ==7:\n",
    "        return Features_Stats_Rois\n",
    "    elif kind == \"valencesbans\" or kind ==8:\n",
    "        return Features_Stats_Valencesbands\n",
    "                                                              \n",
    "    else:\n",
    "        raise NameError('Invalid kind of output')\n",
    "\n",
    "# Unused\n",
    "def graficar(F1_test,emocion):  \n",
    "    Bandas=np.arange(1,6)\n",
    "    contador=1\n",
    "    Emocion=['Valence','Arousal','Dominance','Liking']\n",
    "    for s in range(0,32):\n",
    "        plt.figure(contador,figsize=(6,5))\n",
    "        plt.title('Sujeto de estudio: '+str(s+1)+'  Emocion: '+Emocion[emocion])\n",
    "        plt.bar(Bandas, F1_test[s,emocion,:], align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan'])\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel('Frequency Band')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.show()\n",
    "        contador+=1\n",
    "\n",
    "# This funtion is used to find the hyperparameter c and gamma\n",
    "def svc_param_selection(X, y, nfolds,Gamma):\n",
    "    Cs = 1.**np.arange(0,1)\n",
    "    #gammas = 2.**np.arange(-8,8)\n",
    "    param_grid = {'C':Cs}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf',gamma=Gamma,class_weight = 'balanced'),param_grid,  cv=nfolds)\n",
    "   # print(y)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM KERNEL RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 40 bands: \n",
    "### Here it was performed a classification for each valence and it was combined the bands and ROIs in a single dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\anaconda3\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 4 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8ec4db44ee01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFeatures_Stats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharacterization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEEG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_valences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"sym8\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-8811a6e55e6a>\u001b[0m in \u001b[0;36mcharacterization\u001b[1;34m(Filtered_Data, num_valences, num_trials, num_channels, wave, kind)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mroi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROIS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDWT_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mROI_ALL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDWT_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mROIS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we compute the mean of all channels of the same ROI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;31m#Statistical Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mFeatures_Stats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROI_ALL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# max value feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
     ]
    }
   ],
   "source": [
    "Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,\"sym8\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e232887a5df9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwave\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mFeatures_Stats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharacterization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEEG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_valences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwave_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mN_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossVal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFeatures_Stats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mF1_test_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_folds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mValences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_Band\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8811a6e55e6a>\u001b[0m in \u001b[0;36mcharacterization\u001b[1;34m(Filtered_Data, num_valences, num_trials, num_channels, wave, kind)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mroi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROIS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDWT_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mROI_ALL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDWT_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mROIS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we compute the mean of all channels of the same ROI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;31m#Statistical Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mFeatures_Stats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROI_ALL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mband\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# max value feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences = 3\n",
    "N_Band= 40\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],1)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    #SVM_Prediction_test=np.zeros([Valences,N_folds,N_Band])\n",
    "    \n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence))\n",
    "\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[valence,1,:,:]),label_matrix):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            #print(ytest.shape,y_test.shape)\n",
    "            y_test.append(ytest)\n",
    "                        \n",
    "            for band in range(0,N_Band):        \n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats[valence,band,train_index,:]), (Features_Stats[valence,band,test_index,:])\n",
    "                scaler = MinMaxScaler();\n",
    "                Xtrain = scaler.fit_transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                Xtrain = normalize(Xtrain)\n",
    "                Xtest = normalize(Xtest)\n",
    "\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= stats.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "                SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "                SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "                F1_test_fold[fold,valence,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "                ACC_test_fold[fold,valence,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "                #print(y_test)\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        \n",
    "        for band in range(0,N_Band):\n",
    "            #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "            F1_test[valence,band] = np.mean(F1_test_fold[:,valence,band])\n",
    "            ACC_test[valence,band]= np.mean(ACC_test_fold[:,valence,band])\n",
    "            STD_F1_test[valence,band] = np.std(F1_test_fold[:,valence,band])\n",
    "            STD_ACC_test[valence,band] = np.std(ACC_test_fold[:,valence,band])\n",
    "        print(F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'bandrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    \n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 5 bands:\n",
    "### Here it was performed a classification for each valence and it was combined the rois and statistical featues in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences =3\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],6)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence))\n",
    "\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[valence,1,:,:])):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            #print(ytest.shape,y_test.shape)\n",
    "            y_test.append(ytest)\n",
    "                        \n",
    "            for band in range(0,N_Band):        \n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats[valence,band,train_index,:]), (Features_Stats[valence,band,test_index,:])\n",
    "                scaler = MinMaxScaler();\n",
    "                Xtrain = scaler.fit_transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                Xtrain = normalize(Xtrain)\n",
    "                Xtest = normalize(Xtest)\n",
    "\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= stats.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "                SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "                SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "                F1_test_fold[fold,valence,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "                ACC_test_fold[fold,valence,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "                #print(y_test)\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        for band in range(0,N_Band):\n",
    "            #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "            F1_test[valence,band] = np.mean(F1_test_fold[:,valence,band])\n",
    "            ACC_test[valence,band]= np.mean(ACC_test_fold[:,valence,band])\n",
    "            STD_F1_test[valence,band] = np.std(F1_test_fold[:,valence,band])\n",
    "            STD_ACC_test[valence,band] = np.std(ACC_test_fold[:,valence,band])\n",
    "        print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'bands'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 3 valences and 8 rois:\n",
    "### Here it was performed a classification for each valence and it was combined bands and statistical featues in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Valences =3\n",
    "N_Band=8\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],7)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    \n",
    "    for valence in range(Valences):\n",
    "        y_test = []\n",
    "        print('Analizando Wavelet: '+wave_name[wave]+' Valencia : '+str(valence))\n",
    "\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[valence,1,:,:])):\n",
    "            ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            #print(ytest.shape,y_test.shape)\n",
    "            y_test.append(ytest)\n",
    "                        \n",
    "            for band in range(0,N_Band):        \n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats[valence,band,train_index,:]), (Features_Stats[valence,band,test_index,:])\n",
    "                scaler = MinMaxScaler();\n",
    "                Xtrain = scaler.fit_transform(Xtrain)\n",
    "                Xtest = scaler.transform(Xtest)\n",
    "                Xtrain = normalize(Xtrain)\n",
    "                Xtest = normalize(Xtest)\n",
    "\n",
    "                Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                Median= stats.median(Distances)\n",
    "                Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "                SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "                SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "                F1_test_fold[fold,valence,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "                ACC_test_fold[fold,valence,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "                #print(y_test)\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        for band in range(0,N_Band):\n",
    "            #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "            F1_test[valence,band] = np.mean(F1_test_fold[:,valence,band])\n",
    "            ACC_test[valence,band]= np.mean(ACC_test_fold[:,valence,band])\n",
    "            STD_F1_test[valence,band] = np.std(F1_test_fold[:,valence,band])\n",
    "            STD_ACC_test[valence,band] = np.std(ACC_test_fold[:,valence,band])\n",
    "        print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences_'+'rois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 40 bands and no-valences:\n",
    "### Here it was classified combining the bands and ROIs in a single dimension, and valences with statistical features in another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "N_Band=40\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],4)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "    #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "    #Calcular F1_test\n",
    "    #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "    print(F1_test,ACC_test,STD_F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_bandrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 5 bands and no-valences:\n",
    "### Here it was classified combining the valences, bands and ROIs in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],3)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "       \n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valencesrois'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F1_test_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using 8 Rois and no-valences:\n",
    "### Here it was classified combining the valences, bands and ROIs in a single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=8\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "#C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "#N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],8)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,N_Band])\n",
    "    F1_test = np.zeros([N_Band])\n",
    "    ACC_test = np.zeros([N_Band])\n",
    "    STD_F1_test = np.zeros([N_Band])\n",
    "    STD_ACC_test = np.zeros([N_Band])\n",
    "    y_test = []\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "            Xtrain = normalize(Xtrain)\n",
    "            Xtest = normalize(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "            F1_test_fold[fold,band] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "            ACC_test_fold[fold,band]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "            #print(\"y_test:\",y_test[fold].T[0],\"SVM:\",SVM_Prediction_test,\"ACC:\",ACC_test_fold[fold],\"F1:\",F1_test_fold[fold],\"C:\",Parameters_grid['C'])\n",
    "       \n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = np.mean(F1_test_fold[:,band])\n",
    "        ACC_test[band]= np.mean(ACC_test_fold[:,band])\n",
    "        STD_F1_test[band] = np.std(F1_test_fold[:,band])\n",
    "        STD_ACC_test[band] = np.std(ACC_test_fold[:,band])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valencesbands'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR USE ALL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold as KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "CrossVal = KFold(n_splits=25,shuffle=False)\n",
    "\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],2)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds])\n",
    "    ACC_test_fold = np.zeros([N_folds])\n",
    "    \n",
    "    y_test = []\n",
    "  \n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[:,:]),label_matrix):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "     \n",
    "        Xtrain,Xtest = Features_Stats[train_index,:], Features_Stats[test_index,:]\n",
    "        scaler = MinMaxScaler();\n",
    "        Xtrain = scaler.fit_transform(Xtrain)\n",
    "        Xtest = scaler.transform(Xtest)\n",
    "        Xtrain = normalize(Xtrain)\n",
    "        Xtest = normalize(Xtest)\n",
    "\n",
    "        Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "        Median= stats.median(Distances)\n",
    "        Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "        Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "        SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "        SVM_Classifier.fit(Xtrain,ytrain)\n",
    "        #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "        SVM_Prediction_test= SVM_Classifier.predict(Xtest)\n",
    "        F1_test_fold[fold] = f1_score(y_test[fold].T[0],SVM_Prediction_test,zero_division=1)\n",
    "        ACC_test_fold[fold]= acc(y_test[fold].T[0],SVM_Prediction_test)\n",
    "        print(\"FOLD:\",fold,\"\\n ytest:\",ytest,\" SVM_Prediction_test:\",SVM_Prediction_test)\n",
    "\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "\n",
    "    F1_test = np.mean(F1_test_fold[:])\n",
    "    ACC_test= np.mean(ACC_test_fold[:])\n",
    "    STD_F1_test = np.std(F1_test_fold[:])\n",
    "    STD_ACC_test = np.std(ACC_test_fold[:])\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_all'\n",
    "    \n",
    "     #Pickle save F1_Score\n",
    "    path_save = \"Wavelets_Results_ROIs_2021/\"\n",
    "    \n",
    "    import pickle\n",
    "    file= open(path_save+'F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open(path_save+'ACC_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'ACC_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD\n",
    "    file= open(path_save+'STD_F1_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_F1_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "        \n",
    "        \n",
    "    #Pickle Save STD ACC\n",
    "    file= open(path_save+'STD_ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(STD_ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open(path_save+'STD_ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == STD_ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "                \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1:\",F1_test)\n",
    "print(\"ACC:\",ACC_test)\n",
    "print(\"STD_F1:\",STD_F1_test)\n",
    "print(\"STD_ACC:\",STD_ACC_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR USE ALL VALENCES VECTORIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "N_Band=5\n",
    "CrossVal = KFold(n_splits=50,shuffle=False)\n",
    "C = 2.**np.arange(-15,16)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix)\n",
    "N_cs = len(C)\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "wave_name= ['bior3.3','bior6.8','sym2','sym5','sym8','coif1','coif5','db4','db10','db15']\n",
    "\n",
    "for wave in range(4,5): \n",
    "    Features_Stats=characterization(EEG,num_valences,num_trials,num_channels,wave_name[wave],2)\n",
    "    N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats[0,:,:]))\n",
    "    F1_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    ACC_test_fold = np.zeros([N_folds,Valences,N_Band])\n",
    "    F1_test = np.zeros([Valences,N_Band])\n",
    "    ACC_test = np.zeros([Valences,N_Band])\n",
    "    STD_F1_test = np.zeros([Valences,N_Band])\n",
    "    STD_ACC_test = np.zeros([Valences,N_Band])\n",
    "    \n",
    "    print('Analizando Wavelet: '+wave_name[wave])\n",
    "\n",
    "    fold = 0\n",
    "    for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats[1,:,:])):\n",
    "        ytrain, ytest = label_matrix[train_index], label_matrix[test_index]\n",
    "        #print(emo,sub,fold,test_index)\n",
    "        #print(ytest.shape,y_test.shape)\n",
    "        y_test.append(ytest)\n",
    "\n",
    "        for band in range(0,N_Band):        \n",
    "            Xtrain,Xtest = np.squeeze(Features_Stats[band,train_index,:]), (Features_Stats[band,test_index,:])\n",
    "            scaler = MinMaxScaler();\n",
    "            Xtrain = scaler.fit_transform(Xtrain)\n",
    "            Xtest = scaler.transform(Xtest)\n",
    "\n",
    "            Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "            Median= stats.median(Distances)\n",
    "            Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "            Parameters_grid = svc_param_selection(Xtrain,ytrain,5,Gamma)\n",
    "            SVM_Classifier= svm.SVC(kernel='rbf',C=Parameters_grid['C'],gamma=Gamma,class_weight = 'balanced')\n",
    "            SVM_Classifier.fit(Xtrain,ytrain)\n",
    "            #SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "            SVM_Prediction_test[fold,band]= SVM_Classifier.predict(Xtest)\n",
    "            #print(y_test)\n",
    "        fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "    print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "    for band in range(0,N_Band):\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band])\n",
    "        F1_test[band] = f1_score(y_test,SVM_Prediction_test[:,band])\n",
    "        ACC_test[band] = acc(y_test,SVM_Prediction_test[:,band])\n",
    "    print(F1_test)\n",
    "        \n",
    "\n",
    "    wav= wave_name[wave]+'_valences'\n",
    "    \n",
    "    #Pickle save F1_Score\n",
    "    import pickle\n",
    "    file= open('Wavelets_Results_ROIs/F1_Score_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(F1_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/F1_Score_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == F1_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "    \n",
    "    #Pickle save Features_Stats\n",
    "    file= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(Features_Stats,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/Features_Stats_Wavelets_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == Features_Stats).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    #Pickle Save Accuracy\n",
    "    file= open('Wavelets_Results_ROIs/ACC_'+wav+'.pckl', 'wb')\n",
    "    pickle.dump(ACC_test,file)\n",
    "    file.close()\n",
    "\n",
    "    File= open('Wavelets_Results_ROIs/ACC_'+wav+'.pckl', 'rb')\n",
    "    Load = pickle.load(File)\n",
    "    File.close()\n",
    "    print(Load.shape)\n",
    "    if (Load == ACC_test).all:\n",
    "        print(\"Excelente ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘\")\n",
    "    else:\n",
    "        print(\"Sigue intentando\")\n",
    "\n",
    "    print('SE GUARDÃ“ EL ARCHIVO '+wav) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ACC_test)\n",
    "mean=np.mean(ACC_test)\n",
    "sd = np.std(ACC_test)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import f1_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#---Vars Definition-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Subjects = 32\n",
    "N_Emociones=4\n",
    "N_Band=6\n",
    "CrossVal = LeaveOneOut()\n",
    "N_folds = CrossVal.get_n_splits(np.squeeze(Features_Stats_Wavelets[0,0,:,:]))\n",
    "print(N_folds)\n",
    "C = 2.**np.arange(-15,19)\n",
    "#SVM_C=Moda(N_Emociones,N_Band,Subjects,Best_C_Matrix_C3)\n",
    "N_cs = len(C)\n",
    "Best_C_Matrix=np.zeros([Subjects,N_Emociones,N_folds,N_Band])\n",
    "F1_train = np.zeros([Subjects,N_Emociones,N_folds,N_Band,N_cs])\n",
    "F1_test = np.zeros([Subjects,N_Emociones,N_Band])\n",
    "SVM_Prediction_test=np.zeros([Subjects,N_Emociones,N_folds,N_Band])\n",
    "y_test = np.zeros([Subjects,N_Emociones,N_folds])\n",
    "\n",
    "#---Iterations for each subject-------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "for emo in range(N_Emociones):\n",
    "    for sub in range(Subjects):\n",
    "        print('AnÃ¡lisis Sujeto: ',sub)\n",
    "        if sub==26 and emo==2:\n",
    "            print(emo,' SALTO DE SUJETO ',sub)\n",
    "            sub+=1\n",
    "        emocion=emo\n",
    "        fold = 0\n",
    "        for train_index, test_index in CrossVal.split(np.squeeze(Features_Stats_Wavelets[sub,5,:,:])):\n",
    "            ytrain, ytest = label_threshold_matrix_5[sub,train_index,emocion], label_threshold_matrix_5[sub,test_index,emocion]\n",
    "            #print(emo,sub,fold,test_index)\n",
    "            y_test[sub,emo,fold] = ytest\n",
    "            for band in range(0,N_Band):\n",
    "                Xtrain,Xtest = np.squeeze(Features_Stats_Wavelets[sub,band,train_index,:]), (Features_Stats_Wavelets[sub,band,test_index,:])\n",
    "                Best_C= -10000\n",
    "                Best_F1=0\n",
    "                for c in range(len(C)):\n",
    "                    Distances= scipy.spatial.distance.pdist(Xtrain, metric='euclidean')\n",
    "                    Median= stats.median(Distances)\n",
    "                    Gamma= 1/(Xtrain.shape[1]*Xtrain.var())\n",
    "                    SVM_Classifier= svm.SVC(kernel='rbf',C=C[c],gamma=Gamma)\n",
    "                    SVM_Classifier.fit(Xtrain,ytrain)\n",
    "                    SVM_Prediction_train= SVM_Classifier.predict(Xtrain)\n",
    "                    SVM_Prediction_test[sub,emo,fold,band]= SVM_Classifier.predict(Xtest)\n",
    "                    F1_train[sub,emo,fold,band,c]= f1_score(ytrain,SVM_Prediction_train,average='macro')\n",
    "\n",
    "                    if F1_train[sub,emo,fold,band,c]>Best_F1:\n",
    "                        Best_C_Matrix[sub,emo,fold,band]=C[c]\n",
    "                        Best_C= C[c]\n",
    "                        Best_F1=F1_train[sub,emo,fold,band,c]\n",
    "            fold+=1\n",
    "        #---F1-score evaluartion for test set---------------------------------------------------------------------------------------              \n",
    "        print('INICIO TEST')\n",
    "        #Calcular F1_test\n",
    "        #print(y_test[sub,:],SVM_Prediction_test[sub,:,band,c])\n",
    "        for band in range(0,N_Band):\n",
    "            F1_test[sub,emo,band] = f1_score(y_test[sub,emo,:],SVM_Prediction_test[sub,emo,:,band],average='macro')\n",
    "        print(F1_test[sub])\n",
    "\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
